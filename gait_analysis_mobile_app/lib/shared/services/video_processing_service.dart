import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'dart:isolate';
import 'package:flutter/foundation.dart';
import 'package:path_provider/path_provider.dart';
import 'package:image/image.dart' as img;

import '../../core/constants/app_constants.dart';
import '../models/gait_analysis_models.dart';
import 'ml_service.dart';

/// ë¹„ë””ì˜¤ ì²˜ë¦¬ ì„œë¹„ìŠ¤ ì¶”ìƒ í´ë˜ìŠ¤
abstract class VideoProcessingService {
  Future<GaitAnalysisResult> processVideo(String videoPath, {String? patientId});
  Future<List<PoseLandmark>> processFrame(Uint8List frameData);
  Stream<VideoProcessingProgress> processVideoStream(String videoPath);
  Future<void> cancelProcessing();
}

/// ë¹„ë””ì˜¤ ì²˜ë¦¬ ì§„í–‰ ìƒíƒœ
class VideoProcessingProgress {
  final int currentFrame;
  final int totalFrames;
  final double percentage;
  final String status;
  final List<PoseLandmark>? currentLandmarks;

  const VideoProcessingProgress({
    required this.currentFrame,
    required this.totalFrames,
    required this.percentage,
    required this.status,
    this.currentLandmarks,
  });

  VideoProcessingProgress copyWith({
    int? currentFrame,
    int? totalFrames,
    double? percentage,
    String? status,
    List<PoseLandmark>? currentLandmarks,
  }) {
    return VideoProcessingProgress(
      currentFrame: currentFrame ?? this.currentFrame,
      totalFrames: totalFrames ?? this.totalFrames,
      percentage: percentage ?? this.percentage,
      status: status ?? this.status,
      currentLandmarks: currentLandmarks ?? this.currentLandmarks,
    );
  }
}

/// ë¹„ë””ì˜¤ ì²˜ë¦¬ ì„œë¹„ìŠ¤ êµ¬í˜„
class VideoProcessingServiceImpl implements VideoProcessingService {
  final MLService _mlService;
  StreamController<VideoProcessingProgress>? _progressController;
  Isolate? _processingIsolate;
  bool _isProcessing = false;
  bool _isCancelled = false;

  VideoProcessingServiceImpl({required MLService mlService})
      : _mlService = mlService;

  @override
  Future<GaitAnalysisResult> processVideo(
    String videoPath, {
    String? patientId,
  }) async {
    if (_isProcessing) {
      throw VideoProcessingException('Already processing a video');
    }

    _isProcessing = true;
    _isCancelled = false;

    try {
      // ML ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
      await _mlService.initialize();

      final startTime = DateTime.now();
      print('ğŸ¬ Starting video processing: $videoPath');

      // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
      final videoInfo = await _extractVideoInfo(videoPath);
      print('ğŸ“Š Video info: ${videoInfo.duration}s, ${videoInfo.frameCount} frames');

      // í”„ë ˆì„ ì¶”ì¶œ ë° ì²˜ë¦¬
      final frames = await _extractAndProcessFrames(videoPath, videoInfo);

      if (_isCancelled) {
        throw VideoProcessingException('Processing cancelled');
      }

      // ë³´í–‰ ë¶„ì„ ìˆ˜í–‰
      final gaitParameters = await _analyzeGaitFromFrames(frames);

      // ë³‘ì  ë³´í–‰ ê²€ì¶œ
      final gaitFeatures = GaitFeatures.fromGaitParameters(gaitParameters);
      final pathologicalResult = await _mlService.detectPathologicalGait(gaitFeatures);

      // ê²°ê³¼ ìƒì„±
      final processingTime = DateTime.now().difference(startTime);
      final result = GaitAnalysisResult(
        id: _generateResultId(),
        timestamp: DateTime.now(),
        patientId: patientId,
        videoPath: videoPath,
        duration: videoInfo.duration,
        frameCount: videoInfo.frameCount,
        processingTime: processingTime.inMilliseconds,
        gaitParameters: gaitParameters,
        frames: frames,
        qualityScore: _calculateQualityScore(frames, gaitParameters),
        recommendations: _generateRecommendations(gaitParameters, pathologicalResult),
        pathologicalResult: pathologicalResult,
      );

      print('âœ… Video processing completed: ${processingTime.inSeconds}s');
      return result;
    } catch (e) {
      print('âŒ Video processing failed: $e');
      throw VideoProcessingException('Failed to process video: $e');
    } finally {
      _isProcessing = false;
      _isCancelled = false;
    }
  }

  @override
  Stream<VideoProcessingProgress> processVideoStream(String videoPath) {
    if (_progressController != null) {
      _progressController!.close();
    }

    _progressController = StreamController<VideoProcessingProgress>.broadcast();
    _processVideoInBackground(videoPath);

    return _progressController!.stream;
  }

  Future<void> _processVideoInBackground(String videoPath) async {
    try {
      await _mlService.initialize();
      final videoInfo = await _extractVideoInfo(videoPath);

      _progressController?.add(VideoProcessingProgress(
        currentFrame: 0,
        totalFrames: videoInfo.frameCount,
        percentage: 0.0,
        status: 'Extracting frames...',
      ));

      final frames = <FrameData>[];
      int frameIndex = 0;

      // í”„ë ˆì„ë³„ ì²˜ë¦¬ (ì‹¤ì‹œê°„ í”¼ë“œë°±)
      await for (final frameData in _extractFramesStream(videoPath)) {
        if (_isCancelled) break;

        try {
          // í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
          final landmarks = await _mlService.extractPoseLandmarks(frameData);

          // ê´€ì ˆ ê°ë„ ê³„ì‚°
          final leftAngles = _calculateJointAngles(landmarks, isLeft: true);
          final rightAngles = _calculateJointAngles(landmarks, isRight: true);

          final frame = FrameData(
            frameNumber: frameIndex,
            timestamp: (frameIndex * 1000 / videoInfo.fps).round(),
            landmarks: landmarks,
            leftJointAngles: leftAngles,
            rightJointAngles: rightAngles,
          );

          frames.add(frame);

          // ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
          final progress = (frameIndex + 1) / videoInfo.frameCount;
          _progressController?.add(VideoProcessingProgress(
            currentFrame: frameIndex + 1,
            totalFrames: videoInfo.frameCount,
            percentage: progress * 0.8, // 80%ëŠ” í”„ë ˆì„ ì²˜ë¦¬
            status: 'Processing frame ${frameIndex + 1}/${videoInfo.frameCount}',
            currentLandmarks: landmarks,
          ));

          frameIndex++;
        } catch (e) {
          print('Frame processing error at $frameIndex: $e');
          // ì—ëŸ¬ê°€ ë°œìƒí•œ í”„ë ˆì„ì€ ê±´ë„ˆë›°ê¸°
        }
      }

      if (!_isCancelled && frames.isNotEmpty) {
        // ë³´í–‰ ë¶„ì„ ìˆ˜í–‰
        _progressController?.add(VideoProcessingProgress(
          currentFrame: frameIndex,
          totalFrames: videoInfo.frameCount,
          percentage: 0.9,
          status: 'Analyzing gait parameters...',
        ));

        final gaitParameters = await _analyzeGaitFromFrames(frames);
        final gaitFeatures = GaitFeatures.fromGaitParameters(gaitParameters);
        final pathologicalResult = await _mlService.detectPathologicalGait(gaitFeatures);

        // ì™„ë£Œ
        _progressController?.add(VideoProcessingProgress(
          currentFrame: frameIndex,
          totalFrames: videoInfo.frameCount,
          percentage: 1.0,
          status: 'Analysis completed',
        ));
      }
    } catch (e) {
      _progressController?.addError(VideoProcessingException('Processing failed: $e'));
    } finally {
      _progressController?.close();
      _progressController = null;
    }
  }

  @override
  Future<List<PoseLandmark>> processFrame(Uint8List frameData) async {
    await _mlService.initialize();
    return await _mlService.extractPoseLandmarks(frameData);
  }

  @override
  Future<void> cancelProcessing() async {
    _isCancelled = true;
    _processingIsolate?.kill();
    _processingIsolate = null;
    _progressController?.close();
    _progressController = null;
    print('ğŸ›‘ Video processing cancelled');
  }

  // ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
  Future<VideoInfo> _extractVideoInfo(String videoPath) async {
    // FFmpegë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í”Œë«í¼ë³„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
    // ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
    return VideoInfo(
      path: videoPath,
      duration: 30, // ì´ˆ
      frameCount: 900, // 30fps * 30ì´ˆ
      fps: 30,
      width: 1280,
      height: 720,
    );
  }

  // í”„ë ˆì„ ì¶”ì¶œ ë° ì²˜ë¦¬
  Future<List<FrameData>> _extractAndProcessFrames(
    String videoPath,
    VideoInfo videoInfo,
  ) async {
    final frames = <FrameData>[];

    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” FFmpegë‚˜ í”Œë«í¼ë³„ API ì‚¬ìš©
    // ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    for (int i = 0; i < videoInfo.frameCount && !_isCancelled; i++) {
      try {
        // ë”ë¯¸ í”„ë ˆì„ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œ)
        final dummyFrameData = _generateDummyFrameData();
        final landmarks = await _mlService.extractPoseLandmarks(dummyFrameData);

        final leftAngles = _calculateJointAngles(landmarks, isLeft: true);
        final rightAngles = _calculateJointAngles(landmarks, isRight: true);

        final frame = FrameData(
          frameNumber: i,
          timestamp: (i * 1000 / videoInfo.fps).round(),
          landmarks: landmarks,
          leftJointAngles: leftAngles,
          rightJointAngles: rightAngles,
        );

        frames.add(frame);

        // ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        if (i % 10 == 0) {
          print('Processed frame $i/${videoInfo.frameCount}');
        }
      } catch (e) {
        print('Error processing frame $i: $e');
      }
    }

    return frames;
  }

  // í”„ë ˆì„ ìŠ¤íŠ¸ë¦¼ ì¶”ì¶œ
  Stream<Uint8List> _extractFramesStream(String videoPath) async* {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ì¶œ
    // ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    for (int i = 0; i < 100; i++) {
      if (_isCancelled) break;
      yield _generateDummyFrameData();
      await Future.delayed(const Duration(milliseconds: 33)); // ~30fps
    }
  }

  // ë”ë¯¸ í”„ë ˆì„ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
  Uint8List _generateDummyFrameData() {
    // 224x224 RGB ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
    final image = img.Image(width: 224, height: 224);
    img.fill(image, color: img.ColorRgb8(128, 128, 128));
    return Uint8List.fromList(img.encodeJpg(image));
  }

  // ë³´í–‰ ë¶„ì„
  Future<GaitParameters> _analyzeGaitFromFrames(List<FrameData> frames) async {
    if (frames.isEmpty) {
      throw VideoProcessingException('No frames to analyze');
    }

    // ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤ ì¤€ë¹„
    final landmarkSequence = frames.map((frame) => frame.landmarks).toList();

    // ML ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´í–‰ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    return await _mlService.analyzeGait(landmarkSequence);
  }

  // ê´€ì ˆ ê°ë„ ê³„ì‚°
  JointAngles _calculateJointAngles(
    List<PoseLandmark> landmarks, {
    bool isLeft = false,
    bool isRight = false,
  }) {
    // MediaPipe í¬ì¦ˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ ê¸°ë°˜ ê°ë„ ê³„ì‚°
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” 3D ë²¡í„° ê³„ì‚° ì‚¬ìš©

    if (isLeft) {
      // ì™¼ìª½ ê´€ì ˆ ê°ë„ ê³„ì‚°
      return const JointAngles(
        hip: 170.0,   // ê³ ê´€ì ˆ ê°ë„
        knee: 160.0,  // ìŠ¬ê´€ì ˆ ê°ë„
        ankle: 90.0,  // ì¡±ê´€ì ˆ ê°ë„
      );
    } else {
      // ì˜¤ë¥¸ìª½ ê´€ì ˆ ê°ë„ ê³„ì‚°
      return const JointAngles(
        hip: 165.0,
        knee: 155.0,
        ankle: 95.0,
      );
    }
  }

  // í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
  int _calculateQualityScore(List<FrameData> frames, GaitParameters parameters) {
    if (frames.isEmpty) return 0;

    // ëœë“œë§ˆí¬ ê°€ì‹œì„± ê¸°ë°˜ í’ˆì§ˆ ê³„ì‚°
    double totalVisibility = 0.0;
    int landmarkCount = 0;

    for (final frame in frames) {
      for (final landmark in frame.landmarks) {
        totalVisibility += landmark.visibility;
        landmarkCount++;
      }
    }

    final averageVisibility = landmarkCount > 0 ? totalVisibility / landmarkCount : 0.0;
    final frameCompleteness = frames.length / 300.0; // ìµœì†Œ 300í”„ë ˆì„ ê¸°ì¤€

    // ë³´í–‰ íŒŒë¼ë¯¸í„° í’ˆì§ˆë„ ê³ ë ¤
    final parameterQuality = parameters.qualityScore / 100.0;

    final overallQuality = (averageVisibility * 0.4 +
        frameCompleteness.clamp(0.0, 1.0) * 0.3 +
        parameterQuality * 0.3);

    return (overallQuality * 100).round().clamp(0, 100);
  }

  // ê¶Œì¥ì‚¬í•­ ìƒì„±
  List<String> _generateRecommendations(
    GaitParameters parameters,
    PathologicalDetectionResult pathologicalResult,
  ) {
    final recommendations = <String>[];

    // ë³‘ì  ë³´í–‰ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    recommendations.addAll(pathologicalResult.recommendations);

    // ë³´í–‰ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    if (parameters.cadence < 100) {
      recommendations.add('ë³´í–‰ ì†ë„ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ìš´ë™ì„ ê¶Œì¥í•©ë‹ˆë‹¤.');
    }
    if (parameters.stepLength < 0.5) {
      recommendations.add('ë³´í­ì„ ëŠ˜ë¦¬ëŠ” ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
    if (parameters.stepWidth > 0.15) {
      recommendations.add('ê· í˜• ê°ê°ì„ í–¥ìƒì‹œí‚¤ëŠ” ìš´ë™ì„ ê¶Œì¥í•©ë‹ˆë‹¤.');
    }

    return recommendations;
  }

  String _generateResultId() {
    return 'analysis_${DateTime.now().millisecondsSinceEpoch}';
  }
}

/// ë¹„ë””ì˜¤ ì •ë³´ ëª¨ë¸
class VideoInfo {
  final String path;
  final int duration; // seconds
  final int frameCount;
  final double fps;
  final int width;
  final int height;

  const VideoInfo({
    required this.path,
    required this.duration,
    required this.frameCount,
    required this.fps,
    required this.width,
    required this.height,
  });
}

/// ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜ˆì™¸ í´ë˜ìŠ¤
class VideoProcessingException implements Exception {
  final String message;
  VideoProcessingException(this.message);

  @override
  String toString() => 'VideoProcessingException: $message';
}