import 'dart:async';
import 'dart:typed_data';
import 'package:camera/camera.dart';
import 'package:image/image.dart' as img;
import '../models/gait_analysis_models.dart';
import 'mediapipe_bridge.dart';
import 'v7_pure3d_service.dart';

/// ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì²˜ë¦¬ ì„œë¹„ìŠ¤
///
/// ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìº¡ì²˜í•˜ê³  MediaPipeë¡œ ì²˜ë¦¬
class RealtimeCameraService {
  final MediaPipeBridge _mediapipe = MediaPipeBridge();
  final V7Pure3DService _v7Service = V7Pure3DService();

  CameraController? _cameraController;
  bool _isProcessing = false;
  bool _isRecording = false;

  // ë…¹í™”ëœ ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤
  final List<List<PoseLandmark>> _recordedLandmarks = [];
  int _recordedFrames = 0;
  DateTime? _recordingStartTime;

  // ì½œë°±
  Function(List<PoseLandmark>)? onLandmarksDetected;
  Function(String)? onStatusUpdate;
  Function(V7DetectionResult)? onAnalysisComplete;

  // ì„¤ì •
  static const int targetFps = 30;
  static const int targetFrames = 180; // 6ì´ˆ @ 30fps
  static const Duration frameDuration = Duration(milliseconds: 33); // ~30fps

  /// ì´ˆê¸°í™”
  Future<void> initialize() async {
    try {
      // MediaPipe ì´ˆê¸°í™”
      await _mediapipe.initialize();
      onStatusUpdate?.call('âœ… MediaPipe ì´ˆê¸°í™” ì™„ë£Œ');

      // ì¹´ë©”ë¼ ì´ˆê¸°í™”
      final cameras = await availableCameras();
      if (cameras.isEmpty) {
        throw CameraException('NO_CAMERA', 'No cameras available');
      }

      // ì „ë©´ ì¹´ë©”ë¼ ì„ íƒ
      final frontCamera = cameras.firstWhere(
        (camera) => camera.lensDirection == CameraLensDirection.front,
        orElse: () => cameras.first,
      );

      _cameraController = CameraController(
        frontCamera,
        ResolutionPreset.medium,
        enableAudio: false,
        imageFormatGroup: ImageFormatGroup.yuv420,
      );

      await _cameraController!.initialize();
      onStatusUpdate?.call('âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ');

    } catch (e) {
      onStatusUpdate?.call('âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      rethrow;
    }
  }

  /// ë…¹í™” ì‹œì‘
  Future<void> startRecording() async {
    if (_cameraController == null || !_cameraController!.value.isInitialized) {
      throw StateError('Camera not initialized');
    }

    if (_isRecording) {
      throw StateError('Already recording');
    }

    _isRecording = true;
    _recordedLandmarks.clear();
    _recordedFrames = 0;
    _recordingStartTime = DateTime.now();

    onStatusUpdate?.call('ğŸ¥ ì´¬ì˜ ì¤‘... (6ì´ˆ)');

    // í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘
    await _cameraController!.startImageStream(_processImageFrame);

    // 6ì´ˆ í›„ ìë™ ì •ì§€
    Timer(const Duration(seconds: 6), () {
      if (_isRecording) {
        stopRecording();
      }
    });
  }

  /// í”„ë ˆì„ ì²˜ë¦¬
  void _processImageFrame(CameraImage image) {
    if (_isProcessing || !_isRecording) return;

    if (_recordedFrames >= targetFrames) {
      stopRecording();
      return;
    }

    _isProcessing = true;

    _processCameraImage(image).then((landmarks) {
      if (landmarks != null && landmarks.isNotEmpty) {
        _recordedLandmarks.add(landmarks);
        _recordedFrames++;

        onLandmarksDetected?.call(landmarks);
        onStatusUpdate?.call('ğŸ¥ ì´¬ì˜ ì¤‘... ($_recordedFrames/$targetFrames)');
      }

      _isProcessing = false;
    }).catchError((error) {
      print('âŒ Frame processing error: $error');
      _isProcessing = false;
    });
  }

  /// ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ MediaPipeë¡œ ì²˜ë¦¬
  Future<List<PoseLandmark>?> _processCameraImage(CameraImage image) async {
    try {
      // CameraImageë¥¼ JPEGë¡œ ë³€í™˜
      final jpegBytes = await _convertCameraImageToJpeg(image);
      if (jpegBytes == null) return null;

      // MediaPipeë¡œ Pose ê²€ì¶œ
      final timestampMs = DateTime.now().millisecondsSinceEpoch;
      final landmarks = await _mediapipe.detectPoseVideo(
        jpegBytes,
        timestampMs: timestampMs,
      );

      return landmarks;
    } catch (e) {
      print('âŒ Image processing error: $e');
      return null;
    }
  }

  /// CameraImageë¥¼ JPEGë¡œ ë³€í™˜
  Future<Uint8List?> _convertCameraImageToJpeg(CameraImage image) async {
    try {
      // YUV420 to RGB
      final int width = image.width;
      final int height = image.height;

      // Create image
      final img.Image rgbImage = img.Image(width: width, height: height);

      // Convert YUV to RGB (simplified - production needs proper conversion)
      final Plane yPlane = image.planes[0];
      final Plane uPlane = image.planes[1];
      final Plane vPlane = image.planes[2];

      for (int y = 0; y < height; y++) {
        for (int x = 0; x < width; x++) {
          final int yIndex = y * yPlane.bytesPerRow + x;
          final int uvIndex = (y ~/ 2) * uPlane.bytesPerRow + (x ~/ 2);

          if (yIndex < yPlane.bytes.length &&
              uvIndex < uPlane.bytes.length &&
              uvIndex < vPlane.bytes.length) {
            final int yValue = yPlane.bytes[yIndex];
            final int uValue = uPlane.bytes[uvIndex];
            final int vValue = vPlane.bytes[uvIndex];

            // YUV to RGB conversion
            int r = (yValue + 1.370705 * (vValue - 128)).toInt();
            int g = (yValue - 0.337633 * (uValue - 128) - 0.698001 * (vValue - 128)).toInt();
            int b = (yValue + 1.732446 * (uValue - 128)).toInt();

            // Clamp values
            r = r.clamp(0, 255);
            g = g.clamp(0, 255);
            b = b.clamp(0, 255);

            rgbImage.setPixelRgba(x, y, r, g, b, 255);
          }
        }
      }

      // Encode to JPEG
      final jpegBytes = img.encodeJpg(rgbImage, quality: 85);
      return Uint8List.fromList(jpegBytes);

    } catch (e) {
      print('âŒ Image conversion error: $e');
      return null;
    }
  }

  /// ë…¹í™” ì¤‘ì§€
  Future<void> stopRecording() async {
    if (!_isRecording) return;

    _isRecording = false;

    try {
      await _cameraController?.stopImageStream();
      onStatusUpdate?.call('âœ… ì´¬ì˜ ì™„ë£Œ - ë¶„ì„ ì¤‘...');

      // V7 Pure 3D ë¶„ì„
      await _analyzeRecording();

    } catch (e) {
      print('âŒ Stop recording error: $e');
      onStatusUpdate?.call('âŒ ì´¬ì˜ ì¤‘ì§€ ì‹¤íŒ¨: $e');
    }
  }

  /// ë…¹í™”ëœ ë°ì´í„° ë¶„ì„
  Future<void> _analyzeRecording() async {
    if (_recordedLandmarks.isEmpty) {
      onStatusUpdate?.call('âŒ ë…¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
      return;
    }

    try {
      // V7 Pure 3D íŠ¹ì§• ì¶”ì¶œ
      final features = _v7Service.extractFeatures(
        _recordedLandmarks,
        targetFps.toDouble(),
      );

      // ë³‘ë¦¬ì  ë³´í–‰ ê²€ì¶œ
      final result = _v7Service.detectPathologicalGait(features);

      onAnalysisComplete?.call(result);
      onStatusUpdate?.call(result.isPathological
          ? 'âš ï¸ ë¹„ì •ìƒ ë³´í–‰ íŒ¨í„´ ê²€ì¶œ'
          : 'âœ… ì •ìƒ ë³´í–‰ íŒ¨í„´');

    } catch (e) {
      print('âŒ Analysis error: $e');
      onStatusUpdate?.call('âŒ ë¶„ì„ ì‹¤íŒ¨: $e');
    }
  }

  /// ì •ë¦¬
  Future<void> dispose() async {
    _isRecording = false;
    _isProcessing = false;

    try {
      if (_cameraController?.value.isStreamingImages ?? false) {
        await _cameraController?.stopImageStream();
      }
    } catch (e) {
      print('Warning: Failed to stop image stream: $e');
    }

    await _cameraController?.dispose();
    _cameraController = null;

    await _mediapipe.dispose();

    _recordedLandmarks.clear();
  }

  /// Getters
  CameraController? get cameraController => _cameraController;
  bool get isRecording => _isRecording;
  int get recordedFrames => _recordedFrames;
  List<List<PoseLandmark>> get recordedLandmarks => _recordedLandmarks;
}

/// ì¹´ë©”ë¼ ì˜ˆì™¸
class CameraException implements Exception {
  final String code;
  final String message;

  CameraException(this.code, this.message);

  @override
  String toString() => 'CameraException[$code]: $message';
}
