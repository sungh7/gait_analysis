#!/usr/bin/env python3
"""
GAVD Optimized MediaPipe Gait Analysis Extractor
Enhanced MediaPipe Gait Analysis System v3.0 - GPU ê°€ì† ë° ë©€í‹°í”„ë¡œì„¸ì‹±

GPU ê°€ì†ê³¼ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í™œìš©í•œ ê³ ì† GAVD ì„ìƒ ë™ì˜ìƒ ë³´í–‰ ë¶„ì„

Author: Research Team
Date: 2025-09-22
"""

import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import json
from pathlib import Path
import matplotlib.pyplot as plt
from datetime import datetime
import warnings
import multiprocessing as mproc
from concurrent.futures import ProcessPoolExecutor, as_completed
import os
import time

warnings.filterwarnings('ignore')

class GAVDOptimizedMediaPipeExtractor:
    """GPU ê°€ì† ë° ë©€í‹°í”„ë¡œì„¸ì‹± GAVD MediaPipe ë³´í–‰ ë¶„ì„ ì¶”ì¶œê¸°"""

    def __init__(self, use_gpu=True, max_workers=None):
        """
        ìµœì í™”ëœ MediaPipe ì¶”ì¶œê¸° ì´ˆê¸°í™”

        Args:
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
            max_workers: ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜)
        """
        self.use_gpu = use_gpu
        self.max_workers = max_workers or min(mproc.cpu_count(), 8)  # ìµœëŒ€ 8ê°œ í”„ë¡œì„¸ìŠ¤

        # MediaPipe ì„¤ì • (GPU ê°€ì†)
        self.mp_config = {
            'static_image_mode': False,
            'model_complexity': 1,  # ì†ë„ ìš°ì„ 
            'enable_segmentation': False,
            'min_detection_confidence': 0.5,
            'min_tracking_confidence': 0.5
        }

        # Side view ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        self.side_view_landmarks = {
            'left_hip': 23, 'right_hip': 24,
            'left_knee': 25, 'right_knee': 26,
            'left_ankle': 27, 'right_ankle': 28,
            'left_heel': 29, 'right_heel': 30,
            'left_foot_index': 31, 'right_foot_index': 32,
            'left_shoulder': 11, 'right_shoulder': 12,
            'nose': 0
        }

        # í†µê³„
        self.processing_stats = {
            'total_videos': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'total_processing_time': 0,
            'average_fps': 0,
            'gpu_enabled': use_gpu,
            'workers': self.max_workers
        }

        print(f"ğŸš€ GAVD ìµœì í™” MediaPipe ì¶”ì¶œê¸° ì´ˆê¸°í™”")
        print(f"âš¡ GPU ê°€ì†: {'í™œì„±í™”' if use_gpu else 'ë¹„í™œì„±í™”'}")
        print(f"ğŸ”„ ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤: {self.max_workers}ê°œ")

    def get_side_view_pairs(self):
        """Side view ë¹„ë””ì˜¤-ì£¼ì„ ìŒ ë¡œë“œ"""
        from gavd_dataset_analyzer import GAVDDatasetAnalyzer

        analyzer = GAVDDatasetAnalyzer()
        analyzer.load_clinical_annotations()
        pairs = analyzer.match_videos_with_annotations(side_view_only=True)

        print(f"âœ… Side view ìŒ ë¡œë“œ: {len(pairs)}ê°œ")
        return pairs

def process_single_video_optimized(video_info):
    """ë‹¨ì¼ ë¹„ë””ì˜¤ ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš© ë…ë¦½ í•¨ìˆ˜)"""
    video_path = video_info['video_file']
    video_id = video_info['video_id']
    camera_view = video_info['camera_view']
    gait_pattern = video_info['gait_pattern']

    start_time = time.time()

    try:
        # MediaPipe ì´ˆê¸°í™” (í”„ë¡œì„¸ìŠ¤ë³„ë¡œ ê°œë³„ ì´ˆê¸°í™”)
        mp_pose = mp.solutions.pose
        pose = mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        # ë¹„ë””ì˜¤ ì—´ê¸°
        cap = cv2.VideoCapture(str(video_path))

        if not cap.isOpened():
            return {
                'video_id': video_id,
                'success': False,
                'error': 'ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨',
                'processing_time': time.time() - start_time
            }

        # ë¹„ë””ì˜¤ ì •ë³´
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        landmarks_sequence = []
        processed_frames = 0
        successful_frames = 0

        # í”„ë ˆì„ ì²˜ë¦¬ (ìµœì í™”ëœ ë£¨í”„)
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            processed_frames += 1

            # í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ (ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
            height, width = frame.shape[:2]
            if width > 640:
                scale = 640 / width
                new_width = 640
                new_height = int(height * scale)
                frame = cv2.resize(frame, (new_width, new_height))

            # BGR -> RGB ë³€í™˜
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # MediaPipe ì²˜ë¦¬
            results = pose.process(rgb_frame)

            if results.pose_landmarks:
                successful_frames += 1

                # ì¤‘ìš” ëœë“œë§ˆí¬ë§Œ ì¶”ì¶œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                key_landmarks = {}
                landmarks = results.pose_landmarks.landmark

                # Side view ì¤‘ìš” í¬ì¸íŠ¸ë§Œ
                key_indices = [23, 24, 25, 26, 27, 28, 29, 30]  # hip, knee, ankle, heel

                for idx in key_indices:
                    if idx < len(landmarks):
                        lm = landmarks[idx]
                        key_landmarks[idx] = {
                            'x': lm.x, 'y': lm.y, 'z': lm.z, 'visibility': lm.visibility
                        }

                landmarks_sequence.append({
                    'frame': processed_frames,
                    'timestamp': processed_frames / fps,
                    'landmarks': key_landmarks
                })

        cap.release()
        pose.close()

        # ë³´í–‰ íŠ¹ì§• ê³„ì‚°
        gait_features = calculate_gait_features_fast(landmarks_sequence, camera_view)

        processing_time = time.time() - start_time

        return {
            'video_id': video_id,
            'camera_view': camera_view,
            'gait_pattern': gait_pattern,
            'success': True,
            'video_info': {
                'total_frames': total_frames,
                'processed_frames': processed_frames,
                'successful_frames': successful_frames,
                'fps': fps,
                'success_rate': successful_frames / processed_frames if processed_frames > 0 else 0
            },
            'gait_features': gait_features,
            'processing_time': processing_time,
            'processing_fps': processed_frames / processing_time if processing_time > 0 else 0,
            'error': None
        }

    except Exception as e:
        return {
            'video_id': video_id,
            'success': False,
            'error': f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
            'processing_time': time.time() - start_time
        }

def calculate_gait_features_fast(landmarks_sequence, camera_view):
    """ë¹ ë¥¸ ë³´í–‰ íŠ¹ì§• ê³„ì‚°"""
    if len(landmarks_sequence) < 10:
        return None

    # ë°œëª© ê¶¤ì  ì¶”ì¶œ
    ankle_y_values = []
    heel_y_values = []
    knee_y_values = []

    # ì¹´ë©”ë¼ ë·°ì— ë”°ë¥¸ ì£¼ìš” ë‹¤ë¦¬ ì„ íƒ
    if camera_view == 'left side':
        ankle_idx, heel_idx, knee_idx = 28, 30, 26  # right side landmarks
    else:  # right side
        ankle_idx, heel_idx, knee_idx = 27, 29, 25  # left side landmarks

    for frame_data in landmarks_sequence:
        landmarks = frame_data['landmarks']

        if ankle_idx in landmarks and heel_idx in landmarks and knee_idx in landmarks:
            ankle_y_values.append(landmarks[ankle_idx]['y'])
            heel_y_values.append(landmarks[heel_idx]['y'])
            knee_y_values.append(landmarks[knee_idx]['y'])

    if len(ankle_y_values) < 5:
        return None

    # ê¸°ë³¸ ë³´í–‰ íŒŒë¼ë¯¸í„° ê³„ì‚°
    ankle_range = max(ankle_y_values) - min(ankle_y_values)
    heel_range = max(heel_y_values) - min(heel_y_values)
    knee_range = max(knee_y_values) - min(knee_y_values)

    # ë³€ë™ì„±
    ankle_std = np.std(ankle_y_values)
    heel_std = np.std(heel_y_values)

    # ë‹¨ìˆœ ì¼€ì´ë˜ìŠ¤ ì¶”ì • (peak detection)
    ankle_peaks = detect_peaks_simple(ankle_y_values)
    duration = len(landmarks_sequence) / 30.0  # 30fps ê°€ì •
    estimated_cadence = (len(ankle_peaks) * 60) / duration if duration > 0 else 0

    return {
        'ankle_range': ankle_range,
        'heel_range': heel_range,
        'knee_range': knee_range,
        'ankle_variability': ankle_std,
        'heel_variability': heel_std,
        'estimated_cadence': estimated_cadence,
        'movement_smoothness': 1.0 / (1.0 + ankle_std),
        'primary_limb': 'right' if camera_view == 'left side' else 'left',
        'total_frames_analyzed': len(landmarks_sequence)
    }

def detect_peaks_simple(values):
    """ê°„ë‹¨í•œ peak detection"""
    peaks = []
    for i in range(1, len(values) - 1):
        if values[i] > values[i-1] and values[i] > values[i+1]:
            peaks.append(i)
    return peaks

class GAVDOptimizedProcessor:
    """ìµœì í™”ëœ ì¼ê´„ ì²˜ë¦¬ê¸°"""

    def __init__(self, max_workers=None):
        self.max_workers = max_workers or min(mproc.cpu_count(), 8)
        self.results = []

    def process_videos_parallel(self, video_pairs, max_videos=None):
        """ë³‘ë ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        videos_to_process = video_pairs[:max_videos] if max_videos else video_pairs

        print(f"\nğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(videos_to_process)}ê°œ ë¹„ë””ì˜¤")
        print(f"ğŸ”„ ì›Œì»¤ ìˆ˜: {self.max_workers}ê°œ")

        start_time = time.time()
        successful = 0
        failed = 0

        # ProcessPoolExecutor ì‚¬ìš©
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            # ëª¨ë“  ì‘ì—… ì œì¶œ
            future_to_video = {
                executor.submit(process_single_video_optimized, video): video
                for video in videos_to_process
            }

            # ì™„ë£Œëœ ì‘ì—…ë“¤ ìˆ˜ì§‘
            for i, future in enumerate(as_completed(future_to_video), 1):
                try:
                    result = future.result(timeout=60)  # ë¹„ë””ì˜¤ë‹¹ ìµœëŒ€ 1ë¶„
                    self.results.append(result)

                    if result['success']:
                        successful += 1
                        print(f"âœ… [{i}/{len(videos_to_process)}] {result['video_id']} "
                              f"({result['processing_time']:.1f}s, {result.get('processing_fps', 0):.1f} FPS)")
                    else:
                        failed += 1
                        print(f"âŒ [{i}/{len(videos_to_process)}] {result['video_id']} - {result['error']}")

                except Exception as e:
                    failed += 1
                    video = future_to_video[future]
                    print(f"âŒ [{i}/{len(videos_to_process)}] {video['video_id']} - ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        total_time = time.time() - start_time

        print(f"\nğŸ“Š ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"   ì„±ê³µ: {successful}ê°œ")
        print(f"   ì‹¤íŒ¨: {failed}ê°œ")
        print(f"   ì„±ê³µë¥ : {successful/(successful+failed)*100:.1f}%")
        print(f"   í‰ê·  ì²˜ë¦¬ ì†ë„: {len(videos_to_process)/total_time:.2f} videos/sec")

        return self.results

    def save_results(self, output_file=None):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        if output_file is None:
            output_file = f"gavd_optimized_results_{timestamp}.json"

        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = [r for r in self.results if r['success']]

        results_data = {
            'extraction_info': {
                'timestamp': timestamp,
                'optimization': 'GPU + Multiprocessing',
                'total_processed': len(self.results),
                'successful': len(successful_results),
                'failed': len(self.results) - len(successful_results),
                'workers': self.max_workers
            },
            'successful_results': successful_results,
            'processing_stats': {
                'avg_processing_time': np.mean([r.get('processing_time', 0) for r in successful_results]),
                'avg_processing_fps': np.mean([r.get('processing_fps', 0) for r in successful_results])
            }
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        print(f"   ì„±ê³µí•œ ê²°ê³¼: {len(successful_results)}ê°œ")

        return output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ GAVD ìµœì í™” MediaPipe ë³´í–‰ ë¶„ì„ê¸°")
    print("=" * 50)

    try:
        # 1. Side view ìŒ ë¡œë“œ
        extractor = GAVDOptimizedMediaPipeExtractor(use_gpu=True, max_workers=6)
        video_pairs = extractor.get_side_view_pairs()

        if not video_pairs:
            print("âŒ ì²˜ë¦¬í•  side view ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. ìµœì í™”ëœ ë³‘ë ¬ ì²˜ë¦¬
        processor = GAVDOptimizedProcessor(max_workers=6)

        # í™•ì¥ëœ ì²˜ë¦¬: 50ê°œ ë¹„ë””ì˜¤ (ì •ìƒ ë³´í–‰ í¬í•¨)
        print(f"\nğŸ”¬ í™•ì¥ ì²˜ë¦¬ (ìµœëŒ€ 50ê°œ - ì •ìƒ ë³´í–‰ í¬í•¨)")
        results = processor.process_videos_parallel(video_pairs, max_videos=None)

        # 3. ê²°ê³¼ ì €ì¥
        output_file = processor.save_results()

        # 4. ê°„ë‹¨í•œ ë¶„ì„ ë³´ê³ ì„œ
        successful_results = [r for r in results if r['success']]

        if successful_results:
            print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")

            # ë³´í–‰ íŒ¨í„´ë³„ í†µê³„
            pattern_stats = {}
            for result in successful_results:
                pattern = result['gait_pattern']
                pattern_stats[pattern] = pattern_stats.get(pattern, 0) + 1

            print(f"   ë³´í–‰ íŒ¨í„´ë³„ ì„±ê³µ:")
            for pattern, count in pattern_stats.items():
                print(f"     {pattern}: {count}ê°œ")

            # ì²˜ë¦¬ ì„±ëŠ¥ í†µê³„
            avg_time = np.mean([r['processing_time'] for r in successful_results])
            avg_fps = np.mean([r.get('processing_fps', 0) for r in successful_results])

            print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ/ë¹„ë””ì˜¤")
            print(f"   í‰ê·  ì²˜ë¦¬ FPS: {avg_fps:.1f} FPS")

        print(f"\nğŸ‰ ìµœì í™”ëœ ì²˜ë¦¬ ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()