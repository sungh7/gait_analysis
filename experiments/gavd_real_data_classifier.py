#!/usr/bin/env python3
"""
GAVD Real Data Gait Classifier
Enhanced MediaPipe Gait Analysis System v3.0 - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ë¥˜ê¸°

ì‹¤ì œ GAVD ìž„ìƒ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë³‘ì ë³´í–‰ ë¶„ë¥˜ ì‹œìŠ¤í…œ

Author: Research Team
Date: 2025-09-22
"""

import numpy as np
import pandas as pd
import json
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class GAVDRealDataClassifier:
    """ì‹¤ì œ GAVD ë°ì´í„° ê¸°ë°˜ ë³‘ì ë³´í–‰ ë¶„ë¥˜ê¸°"""

    def __init__(self, results_file=None):
        """
        ì‹¤ì œ ë°ì´í„° ë¶„ë¥˜ê¸° ì´ˆê¸°í™”

        Args:
            results_file: ìµœì í™”ëœ ì¶”ì¶œ ê²°ê³¼ JSON íŒŒì¼
        """
        self.results_file = results_file
        self.raw_data = None
        self.processed_features = None
        self.labels = None
        self.binary_labels = None

        # ëª¨ë¸ë“¤
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.binary_classifier = None
        self.multiclass_classifier = None
        self.anomaly_detector = None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {}

        print(f"ðŸ¥ GAVD ì‹¤ì œ ë°ì´í„° ë¶„ë¥˜ê¸° ì´ˆê¸°í™”")
        print(f"ðŸ“ ê²°ê³¼ íŒŒì¼: {results_file}")

    def load_extracted_features(self, results_file=None):
        """ì¶”ì¶œëœ íŠ¹ì§• ë°ì´í„° ë¡œë“œ"""
        if results_file:
            self.results_file = results_file

        if not self.results_file or not Path(self.results_file).exists():
            print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.results_file}")
            return False

        print(f"\nðŸ“– ì¶”ì¶œëœ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì¤‘...")

        with open(self.results_file, 'r', encoding='utf-8') as f:
            self.raw_data = json.load(f)

        successful_results = self.raw_data.get('successful_results', [])
        print(f"âœ… ì„±ê³µì ì¸ ê²°ê³¼: {len(successful_results)}ê°œ")

        if len(successful_results) == 0:
            print(f"âŒ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # íŠ¹ì§• ë²¡í„°ì™€ ë¼ë²¨ ì¶”ì¶œ
        feature_vectors = []
        labels = []
        video_info = []

        for result in successful_results:
            if result.get('gait_features') and result.get('success'):
                features = result['gait_features']

                # íŠ¹ì§• ë²¡í„° êµ¬ì„± (ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ë°˜)
                feature_vector = [
                    features.get('ankle_range', 0),
                    features.get('heel_range', 0),
                    features.get('knee_range', 0),
                    features.get('ankle_variability', 0),
                    features.get('heel_variability', 0),
                    features.get('estimated_cadence', 0),
                    features.get('movement_smoothness', 0),
                    features.get('total_frames_analyzed', 0),
                    # ë¹„ë””ì˜¤ í’ˆì§ˆ ì§€í‘œ
                    result['video_info']['success_rate'],
                    result['video_info']['successful_frames'],
                    result['processing_fps'],
                    # ì¶”ê°€ ê³„ì‚°ëœ íŠ¹ì§•
                    features.get('ankle_range', 0) / features.get('heel_range', 1),  # ë°œëª©/ë°œë’¤ê¿ˆì¹˜ ë¹„ìœ¨
                    features.get('estimated_cadence', 0) / 120.0 if features.get('estimated_cadence', 0) > 0 else 0,  # ì •ê·œí™”ëœ ì¼€ì´ë˜ìŠ¤
                    1.0 - features.get('ankle_variability', 0),  # ì•ˆì •ì„± ì§€ìˆ˜
                    features.get('movement_smoothness', 0) * result['video_info']['success_rate']  # ì¢…í•© í’ˆì§ˆ ì§€ìˆ˜
                ]

                feature_vectors.append(feature_vector)
                labels.append(result['gait_pattern'])
                video_info.append({
                    'video_id': result['video_id'],
                    'camera_view': result['camera_view'],
                    'gait_pattern': result['gait_pattern']
                })

        self.processed_features = np.array(feature_vectors)
        self.labels = np.array(labels)
        self.video_info = video_info

        # ì´ì§„ ë¶„ë¥˜ ë¼ë²¨ ìƒì„± (normal vs pathological)
        self.binary_labels = np.array(['normal' if label == 'normal' else 'pathological' for label in self.labels])

        print(f"ðŸ“Š ì²˜ë¦¬ëœ ë°ì´í„°:")
        print(f"   íŠ¹ì§• ë²¡í„°: {self.processed_features.shape}")
        print(f"   ê³ ìœ  íŒ¨í„´: {np.unique(self.labels)}")
        print(f"   íŒ¨í„´ ë¶„í¬: {np.unique(self.labels, return_counts=True)}")

        return True

    def validate_clinical_criteria(self):
        """ìž„ìƒì  ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ê²€ì¦"""
        print(f"\nðŸ¥ ìž„ìƒì  ê¸°ì¤€ ê²€ì¦...")

        if self.processed_features is None:
            print(f"âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ì •ìƒ ë²”ìœ„ ì„¤ì • (ë¬¸í—Œ ê¸°ë°˜)
        clinical_ranges = {
            'cadence': (90, 130),  # steps/min
            'ankle_range': (0.05, 0.3),  # normalized range
            'movement_smoothness': (0.3, 1.0),
            'success_rate': (0.7, 1.0)  # landmark detection quality
        }

        validation_results = {}

        for i, pattern in enumerate(np.unique(self.labels)):
            pattern_mask = self.labels == pattern
            pattern_features = self.processed_features[pattern_mask]

            if len(pattern_features) == 0:
                continue

            # íŒ¨í„´ë³„ íŠ¹ì§• í†µê³„
            cadence_values = pattern_features[:, 5]  # estimated_cadence
            ankle_range_values = pattern_features[:, 0]  # ankle_range
            smoothness_values = pattern_features[:, 6]  # movement_smoothness
            success_rate_values = pattern_features[:, 8]  # success_rate

            validation_results[pattern] = {
                'count': len(pattern_features),
                'cadence': {
                    'mean': np.mean(cadence_values),
                    'std': np.std(cadence_values),
                    'within_normal': np.sum((cadence_values >= clinical_ranges['cadence'][0]) &
                                          (cadence_values <= clinical_ranges['cadence'][1])) / len(cadence_values)
                },
                'ankle_range': {
                    'mean': np.mean(ankle_range_values),
                    'std': np.std(ankle_range_values),
                    'within_normal': np.sum((ankle_range_values >= clinical_ranges['ankle_range'][0]) &
                                          (ankle_range_values <= clinical_ranges['ankle_range'][1])) / len(ankle_range_values)
                },
                'movement_quality': {
                    'smoothness_mean': np.mean(smoothness_values),
                    'success_rate_mean': np.mean(success_rate_values)
                }
            }

        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        print(f"\nðŸ“‹ íŒ¨í„´ë³„ ìž„ìƒì  íŠ¹ì„±:")
        for pattern, stats in validation_results.items():
            print(f"\nðŸ¦´ {pattern} ({stats['count']}ê°œ):")
            print(f"   ì¼€ì´ë˜ìŠ¤: {stats['cadence']['mean']:.1f} Â± {stats['cadence']['std']:.1f} steps/min "
                  f"(ì •ìƒë²”ìœ„ ë‚´: {stats['cadence']['within_normal']*100:.1f}%)")
            print(f"   ë°œëª© ê°€ë™ë²”ìœ„: {stats['ankle_range']['mean']:.3f} Â± {stats['ankle_range']['std']:.3f} "
                  f"(ì •ìƒë²”ìœ„ ë‚´: {stats['ankle_range']['within_normal']*100:.1f}%)")
            print(f"   ì›€ì§ìž„ í’ˆì§ˆ: {stats['movement_quality']['smoothness_mean']:.3f}")
            print(f"   ê²€ì¶œ ì„±ê³µë¥ : {stats['movement_quality']['success_rate_mean']*100:.1f}%")

        self.validation_results = validation_results
        return True

    def train_binary_classifier(self):
        """ì´ì§„ ë¶„ë¥˜ê¸° í›ˆë ¨ (ì •ìƒ vs ë³‘ì )"""
        print(f"\nðŸŽ¯ ì´ì§„ ë¶„ë¥˜ê¸° í›ˆë ¨ (ì •ìƒ vs ë³‘ì )...")

        if self.processed_features is None:
            print(f"âŒ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # í´ëž˜ìŠ¤ ë¶„í¬ í™•ì¸
        unique_binary, counts_binary = np.unique(self.binary_labels, return_counts=True)
        print(f"   ì´ì§„ ë¶„ë¥˜ ë¶„í¬: {dict(zip(unique_binary, counts_binary))}")

        if len(unique_binary) < 2:
            print(f"âŒ ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ í´ëž˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            self.processed_features, self.binary_labels,
            test_size=0.3, random_state=42, stratify=self.binary_labels
        )

        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # ëžœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°
        self.binary_classifier = RandomForestClassifier(
            n_estimators=100,
            max_depth=8,
            random_state=42,
            class_weight='balanced',
            min_samples_split=3,
            min_samples_leaf=2
        )

        # í›ˆë ¨
        self.binary_classifier.fit(X_train_scaled, y_train)

        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = self.binary_classifier.predict(X_test_scaled)
        y_pred_proba = self.binary_classifier.predict_proba(X_test_scaled)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, pos_label='pathological', average='binary')
        recall = recall_score(y_test, y_pred, pos_label='pathological', average='binary')
        f1 = f1_score(y_test, y_pred, pos_label='pathological', average='binary')

        # AUC ê³„ì‚°
        if len(unique_binary) == 2:
            pathological_idx = np.where(self.binary_classifier.classes_ == 'pathological')[0][0]
            auc = roc_auc_score(y_test, y_pred_proba[:, pathological_idx])
        else:
            auc = 0.5

        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(self.binary_classifier, X_train_scaled, y_train,
                                  cv=StratifiedKFold(n_splits=min(5, len(y_train)//2)),
                                  scoring='accuracy')

        self.performance_metrics['binary_classification'] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'auc_roc': auc,
            'cv_accuracy_mean': np.mean(cv_scores),
            'cv_accuracy_std': np.std(cv_scores),
            'train_size': len(X_train),
            'test_size': len(X_test),
            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),
            'classification_report': classification_report(y_test, y_pred, output_dict=True)
        }

        print(f"âœ… ì´ì§„ ë¶„ë¥˜ê¸° í›ˆë ¨ ì™„ë£Œ:")
        print(f"   ì •í™•ë„: {accuracy:.3f}")
        print(f"   ì •ë°€ë„: {precision:.3f}")
        print(f"   ìž¬í˜„ìœ¨: {recall:.3f}")
        print(f"   F1 ì ìˆ˜: {f1:.3f}")
        print(f"   AUC: {auc:.3f}")
        print(f"   êµì°¨ê²€ì¦: {np.mean(cv_scores):.3f} Â± {np.std(cv_scores):.3f}")

        return True

    def train_multiclass_classifier(self):
        """ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ê¸° í›ˆë ¨"""
        print(f"\nðŸŽ­ ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ê¸° í›ˆë ¨...")

        unique_labels, counts = np.unique(self.labels, return_counts=True)
        print(f"   í´ëž˜ìŠ¤ ë¶„í¬: {dict(zip(unique_labels, counts))}")

        # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸ (í´ëž˜ìŠ¤ë‹¹ ìµœì†Œ 3ê°œ)
        min_samples = 3
        valid_classes = [label for label, count in zip(unique_labels, counts) if count >= min_samples]

        if len(valid_classes) < 2:
            print(f"âŒ ë‹¤ì¤‘ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ í´ëž˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ (ìµœì†Œ {min_samples}ê°œ ìƒ˜í”Œ í•„ìš”).")
            return False

        # ìœ íš¨í•œ í´ëž˜ìŠ¤ë§Œ í•„í„°ë§
        valid_mask = np.isin(self.labels, valid_classes)
        X_filtered = self.processed_features[valid_mask]
        y_filtered = self.labels[valid_mask]

        print(f"   í•„í„°ë§ í›„ ìœ íš¨ í´ëž˜ìŠ¤: {valid_classes}")
        print(f"   í•„í„°ë§ í›„ ìƒ˜í”Œ ìˆ˜: {len(X_filtered)}ê°œ")

        # ë ˆì´ë¸” ì¸ì½”ë”©
        y_encoded = self.label_encoder.fit_transform(y_filtered)

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X_filtered, y_encoded,
            test_size=0.3, random_state=42, stratify=y_encoded
        )

        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ (ê¸°ì¡´ scaler ì‚¬ìš©)
        X_train_scaled = self.scaler.transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ê¸°
        self.multiclass_classifier = RandomForestClassifier(
            n_estimators=150,
            max_depth=10,
            random_state=42,
            class_weight='balanced',
            min_samples_split=2,
            min_samples_leaf=1
        )

        # í›ˆë ¨
        self.multiclass_classifier.fit(X_train_scaled, y_train)

        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = self.multiclass_classifier.predict(X_test_scaled)

        accuracy = accuracy_score(y_test, y_pred)
        class_report = classification_report(y_test, y_pred,
                                           target_names=self.label_encoder.classes_,
                                           output_dict=True, zero_division=0)

        self.performance_metrics['multiclass_classification'] = {
            'accuracy': accuracy,
            'valid_classes': valid_classes,
            'classes_count': len(valid_classes),
            'train_size': len(X_train),
            'test_size': len(X_test),
            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),
            'classification_report': class_report
        }

        print(f"âœ… ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ê¸° í›ˆë ¨ ì™„ë£Œ:")
        print(f"   ì •í™•ë„: {accuracy:.3f}")
        print(f"   ìœ íš¨ í´ëž˜ìŠ¤: {len(valid_classes)}ê°œ")

        return True

    def train_anomaly_detector(self):
        """ì´ìƒ ê²€ì¶œê¸° í›ˆë ¨ (ì •ìƒ ë³´í–‰ ê¸°ë°˜)"""
        print(f"\nðŸ” ì´ìƒ ê²€ì¶œê¸° í›ˆë ¨...")

        # ì •ìƒ ë³´í–‰ ë°ì´í„°ë§Œ ì¶”ì¶œ
        normal_mask = self.labels == 'normal'
        normal_features = self.processed_features[normal_mask]

        if len(normal_features) < 5:
            print(f"âŒ ì´ìƒ ê²€ì¶œì„ ìœ„í•œ ì¶©ë¶„í•œ ì •ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ ({len(normal_features)}ê°œ).")
            return False

        print(f"   ì •ìƒ ë³´í–‰ ìƒ˜í”Œ: {len(normal_features)}ê°œ")

        # ì •ìƒ ë°ì´í„°ë¡œ ìŠ¤ì¼€ì¼ë§
        normal_features_scaled = self.scaler.transform(normal_features)

        # Isolation Forest
        isolation_forest = IsolationForest(
            contamination=0.15,  # 15% ì´ìƒì¹˜ í—ˆìš©
            random_state=42,
            n_estimators=100
        )

        # One-Class SVM
        one_class_svm = OneClassSVM(
            nu=0.15,
            kernel='rbf',
            gamma='scale'
        )

        # ì •ìƒ ë°ì´í„°ë¡œ í›ˆë ¨
        isolation_forest.fit(normal_features_scaled)
        one_class_svm.fit(normal_features_scaled)

        self.anomaly_detector = {
            'isolation_forest': isolation_forest,
            'one_class_svm': one_class_svm
        }

        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì´ìƒ ê²€ì¶œ ì„±ëŠ¥ í‰ê°€
        all_features_scaled = self.scaler.transform(self.processed_features)

        # ì‹¤ì œ ë ˆì´ë¸” (ì •ìƒ=1, ë¹„ì •ìƒ=-1)
        true_anomaly_labels = np.array([1 if label == 'normal' else -1 for label in self.labels])

        # ì˜ˆì¸¡
        if_pred = isolation_forest.predict(all_features_scaled)
        svm_pred = one_class_svm.predict(all_features_scaled)

        # ì•™ìƒë¸” ì˜ˆì¸¡ (ë‘ ëª¨ë¸ ëª¨ë‘ ì •ìƒì´ë¼ê³  í•´ì•¼ ì •ìƒ)
        ensemble_pred = np.array([1 if (if_p == 1 and svm_p == 1) else -1
                                for if_p, svm_p in zip(if_pred, svm_pred)])

        # ì„±ëŠ¥ ê³„ì‚°
        anomaly_accuracy = accuracy_score(true_anomaly_labels, ensemble_pred)

        self.performance_metrics['anomaly_detection'] = {
            'accuracy': anomaly_accuracy,
            'normal_samples': len(normal_features),
            'total_samples': len(self.processed_features),
            'isolation_forest_anomalies': np.sum(if_pred == -1),
            'svm_anomalies': np.sum(svm_pred == -1),
            'ensemble_anomalies': np.sum(ensemble_pred == -1)
        }

        print(f"âœ… ì´ìƒ ê²€ì¶œê¸° í›ˆë ¨ ì™„ë£Œ:")
        print(f"   ì •í™•ë„: {anomaly_accuracy:.3f}")
        print(f"   ê²€ì¶œëœ ì´ìƒ: {np.sum(ensemble_pred == -1)}ê°œ")

        return True

    def generate_performance_report(self):
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        print(f"\nðŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±...")

        if not self.performance_metrics:
            print(f"âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        report = f"""
ðŸ¥ GAVD ì‹¤ì œ ìž„ìƒ ë°ì´í„° ê¸°ë°˜ ë³‘ì ë³´í–‰ ë¶„ë¥˜ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ê³ ì„œ
{'='*80}

ðŸ“… ìƒì„± ì¼ì‹œ: {timestamp}
ðŸ“Š ë°ì´í„° ê¸°ë°˜: ì‹¤ì œ GAVD ìž„ìƒ ë¹„ë””ì˜¤ ({len(self.processed_features)}ê°œ)

ðŸ“ˆ ë°ì´í„°ì…‹ ì •ë³´:
   íŠ¹ì§• ì°¨ì›: {self.processed_features.shape[1]}ê°œ
   ì´ ìƒ˜í”Œ: {len(self.processed_features)}ê°œ
   ê³ ìœ  íŒ¨í„´: {len(np.unique(self.labels))}ê°œ
   íŒ¨í„´ ë¶„í¬: {dict(zip(*np.unique(self.labels, return_counts=True)))}

ðŸŽ¯ ì´ì§„ ë¶„ë¥˜ ì„±ëŠ¥ (ì •ìƒ vs ë³‘ì ):"""

        if 'binary_classification' in self.performance_metrics:
            binary_metrics = self.performance_metrics['binary_classification']
            report += f"""
   ì •í™•ë„: {binary_metrics['accuracy']:.3f}
   ì •ë°€ë„: {binary_metrics['precision']:.3f}
   ìž¬í˜„ìœ¨: {binary_metrics['recall']:.3f}
   F1 ì ìˆ˜: {binary_metrics['f1_score']:.3f}
   AUC-ROC: {binary_metrics['auc_roc']:.3f}
   êµì°¨ê²€ì¦ ì •í™•ë„: {binary_metrics['cv_accuracy_mean']:.3f} Â± {binary_metrics['cv_accuracy_std']:.3f}
   í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¹„ìœ¨: {binary_metrics['train_size']}/{binary_metrics['test_size']}"""
        else:
            report += "\n   âŒ ì´ì§„ ë¶„ë¥˜ ê²°ê³¼ ì—†ìŒ"

        report += f"\n\nðŸŽ­ ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ ì„±ëŠ¥:"

        if 'multiclass_classification' in self.performance_metrics:
            multi_metrics = self.performance_metrics['multiclass_classification']
            report += f"""
   ì •í™•ë„: {multi_metrics['accuracy']:.3f}
   ìœ íš¨ í´ëž˜ìŠ¤: {multi_metrics['classes_count']}ê°œ
   í´ëž˜ìŠ¤ ëª©ë¡: {multi_metrics['valid_classes']}
   í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¹„ìœ¨: {multi_metrics['train_size']}/{multi_metrics['test_size']}"""
        else:
            report += "\n   âŒ ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ ê²°ê³¼ ì—†ìŒ"

        report += f"\n\nðŸ” ì´ìƒ ê²€ì¶œ ì„±ëŠ¥:"

        if 'anomaly_detection' in self.performance_metrics:
            anomaly_metrics = self.performance_metrics['anomaly_detection']
            report += f"""
   ì •í™•ë„: {anomaly_metrics['accuracy']:.3f}
   ì •ìƒ ê¸°ì¤€ ìƒ˜í”Œ: {anomaly_metrics['normal_samples']}ê°œ
   ê²€ì¶œëœ ì´ìƒ: {anomaly_metrics['ensemble_anomalies']}ê°œ
   ì´ìƒ ë¹„ìœ¨: {anomaly_metrics['ensemble_anomalies']/anomaly_metrics['total_samples']*100:.1f}%"""
        else:
            report += "\n   âŒ ì´ìƒ ê²€ì¶œ ê²°ê³¼ ì—†ìŒ"

        report += f"""

ðŸ’¡ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì‹œìŠ¤í…œì˜ íŠ¹ì§•:
   âœ… ì‹¤ì œ í™˜ìž ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§• ì‚¬ìš©
   âœ… ìž„ìƒì ìœ¼ë¡œ ì˜ë¯¸ìžˆëŠ” ë³´í–‰ íŒŒë¼ë¯¸í„° ê¸°ë°˜
   âœ… MediaPipe landmark detection í’ˆì§ˆ ê³ ë ¤
   âœ… ë‹¤ì–‘í•œ ì¹´ë©”ë¼ ë·° (left_side, right_side) í†µí•©
   âœ… êµì°¨ê²€ì¦ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€

âš ï¸  ì œí•œì‚¬í•­:
   â€¢ ìƒ˜í”Œ í¬ê¸°ê°€ ì œí•œì  (íŠ¹ížˆ ì¼ë¶€ ë³‘ì  íŒ¨í„´)
   â€¢ ë‹¨ì¼ í”„ë ˆìž„ ë¶„ì„ì´ ì•„ë‹Œ ì‹œê°„ì  íŒ¨í„´ ë¶„ì„ í•„ìš”
   â€¢ ë” ë§Žì€ ìž„ìƒ ê²€ì¦ ë°ì´í„° í•„ìš”

ðŸ”¬ ì´ì „ ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ ëŒ€ë¹„ ê°œì„ ì :
   â€¢ ì‹¤ì œ í™˜ìž ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ì„± í–¥ìƒ
   â€¢ MediaPipe ê²€ì¶œ í’ˆì§ˆì„ ê³ ë ¤í•œ robustí•œ ë¶„ë¥˜
   â€¢ ìž„ìƒì ìœ¼ë¡œ ê²€ì¦ ê°€ëŠ¥í•œ íŠ¹ì§• ì‚¬ìš©
   â€¢ ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì ì ˆí•œ ëª¨ë¸ ë³µìž¡ë„ ì¡°ì ˆ

{'='*80}
ë³´ê³ ì„œ ìƒì„± ì‹œê°„: {timestamp}
"""

        print(report)

        # ë³´ê³ ì„œ íŒŒì¼ ì €ìž¥
        report_file = f"gavd_real_data_classification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ðŸ“„ ë³´ê³ ì„œ ì €ìž¥: {report_file}")
        return report

    def save_models(self):
        """í›ˆë ¨ëœ ëª¨ë¸ ì €ìž¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_dir = Path(f"gavd_real_models_{timestamp}")
        model_dir.mkdir(exist_ok=True)

        # ëª¨ë¸ë“¤ ì €ìž¥
        if self.binary_classifier:
            joblib.dump(self.binary_classifier, model_dir / "binary_classifier.pkl")

        if self.multiclass_classifier:
            joblib.dump(self.multiclass_classifier, model_dir / "multiclass_classifier.pkl")
            joblib.dump(self.label_encoder, model_dir / "label_encoder.pkl")

        if self.anomaly_detector:
            joblib.dump(self.anomaly_detector, model_dir / "anomaly_detector.pkl")

        joblib.dump(self.scaler, model_dir / "feature_scaler.pkl")

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ìž¥
        with open(model_dir / "performance_metrics.json", 'w', encoding='utf-8') as f:
            json.dump(self.performance_metrics, f, indent=2, ensure_ascii=False)

        print(f"\nðŸ’¾ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_dir}")
        return model_dir

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ðŸ¥ GAVD ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë³‘ì ë³´í–‰ ë¶„ë¥˜ê¸°")
    print("=" * 60)

    # ìµœì‹  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
    result_files = list(Path(".").glob("gavd_optimized_results_*.json"))
    if not result_files:
        print("âŒ ì¶”ì¶œ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € gavd_optimized_mediapipe_extractor.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
    print(f"ðŸ“ ì‚¬ìš©í•  ê²°ê³¼ íŒŒì¼: {latest_file}")

    try:
        # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        classifier = GAVDRealDataClassifier(str(latest_file))

        # 1. íŠ¹ì§• ë°ì´í„° ë¡œë“œ
        if not classifier.load_extracted_features():
            return

        # 2. ìž„ìƒì  ê²€ì¦
        classifier.validate_clinical_criteria()

        # 3. ëª¨ë¸ í›ˆë ¨
        print(f"\nðŸš€ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œìž‘...")

        # ì´ì§„ ë¶„ë¥˜ê¸°
        classifier.train_binary_classifier()

        # ë‹¤ì¤‘ í´ëž˜ìŠ¤ ë¶„ë¥˜ê¸°
        classifier.train_multiclass_classifier()

        # ì´ìƒ ê²€ì¶œê¸°
        classifier.train_anomaly_detector()

        # 4. ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±
        classifier.generate_performance_report()

        # 5. ëª¨ë¸ ì €ìž¥
        model_dir = classifier.save_models()

        print(f"\nðŸŽ‰ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ ì™„ë£Œ!")
        print(f"ðŸ’¾ ëª¨ë¸ ì €ìž¥ ìœ„ì¹˜: {model_dir}")

    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()