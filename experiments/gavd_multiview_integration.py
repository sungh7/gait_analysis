#!/usr/bin/env python3
"""
GAVD Multi-View Gait Analysis Integration
Enhanced MediaPipe Gait Analysis System v2.0 - GAVD Integration

ë‹¤ì¤‘ ì¹´ë©”ë¼ ë·° í†µí•© ë³´í–‰ ë¶„ì„ ì‹œìŠ¤í…œ

Author: Research Team
Date: 2025-09-22
"""

import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import json
from pathlib import Path
import matplotlib.pyplot as plt
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import threading
from collections import defaultdict

class GAVDMultiViewGaitAnalyzer:
    """GAVD ë‹¤ì¤‘ ë·° ë³´í–‰ ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self, gavd_path="/data/datasets/GAVD", gavd_analysis_file=None):
        """
        ë‹¤ì¤‘ ë·° ë³´í–‰ ë¶„ì„ê¸° ì´ˆê¸°í™”

        Args:
            gavd_path: GAVD ë°ì´í„°ì…‹ ê²½ë¡œ
            gavd_analysis_file: GAVD ë¶„ì„ ê²°ê³¼ íŒŒì¼
        """
        self.gavd_path = Path(gavd_path)
        self.videos_path = self.gavd_path / "videos_cut_by_view"
        self.data_path = self.gavd_path / "data"
        self.gavd_analysis_file = gavd_analysis_file

        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils

        # ë‹¤ì¤‘ ë·° ë°ì´í„°
        self.multi_view_videos = {}
        self.view_features = {}
        self.integrated_features = {}

        # ì¹´ë©”ë¼ ë·° ì„¤ì •
        self.camera_views = {
            'front': {'weight': 1.0, 'primary_joints': ['hip', 'knee', 'ankle']},
            'back': {'weight': 0.8, 'primary_joints': ['hip', 'spine']},
            'left_side': {'weight': 1.2, 'primary_joints': ['hip', 'knee', 'ankle', 'stride']},
            'right_side': {'weight': 1.2, 'primary_joints': ['hip', 'knee', 'ankle', 'stride']}
        }

        print(f"ğŸ¥ GAVD ë‹¤ì¤‘ ë·° ë³´í–‰ ë¶„ì„ê¸° ì´ˆê¸°í™”")
        print(f"ğŸ“ ë¹„ë””ì˜¤ ê²½ë¡œ: {self.videos_path}")
        print(f"ğŸ” ì§€ì› ì¹´ë©”ë¼ ë·°: {list(self.camera_views.keys())}")

    def load_multi_view_data(self):
        """ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ë°ì´í„° ë¡œë“œ"""
        print(f"\nğŸ“– ë‹¤ì¤‘ ë·° ë°ì´í„° ë¡œë“œ ì¤‘...")

        # GAVD ë¶„ì„ ê²°ê³¼ì—ì„œ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì°¾ê¸°
        if self.gavd_analysis_file and Path(self.gavd_analysis_file).exists():
            with open(self.gavd_analysis_file, 'r', encoding='utf-8') as f:
                gavd_analysis = json.load(f)

            # ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì¶”ì¶œ
            unique_videos = gavd_analysis.get('pathological_patterns', {}).get('unique_videos', [])

            for video_info in unique_videos:
                video_id = video_info['id']
                cam_views = video_info['cam_view']
                gait_pattern = video_info['gait_pat']

                if len(cam_views) > 1:  # ë‹¤ì¤‘ ë·°ë§Œ ì„ íƒ
                    self.multi_view_videos[video_id] = {
                        'views': cam_views,
                        'gait_pattern': gait_pattern,
                        'dataset_type': video_info.get('dataset', 'Unknown'),
                        'video_files': {}
                    }

                    # ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ ë§¤ì¹­
                    for view in cam_views:
                        video_pattern = f"{video_id}_{view}_*.mp4"
                        matching_files = list(self.videos_path.glob(video_pattern))

                        if matching_files:
                            self.multi_view_videos[video_id]['video_files'][view] = str(matching_files[0])

        else:
            # GAVD ë¶„ì„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì§ì ‘ ìŠ¤ìº”
            print(f"âš ï¸  GAVD ë¶„ì„ íŒŒì¼ì´ ì—†ì–´ ì§ì ‘ ë¹„ë””ì˜¤ ìŠ¤ìº”")
            self.scan_multi_view_videos()

        print(f"âœ… ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ {len(self.multi_view_videos)}ê°œ ë°œê²¬")

        # ë‹¤ì¤‘ ë·° í†µê³„
        view_count_dist = defaultdict(int)
        pattern_dist = defaultdict(int)

        for video_id, video_info in self.multi_view_videos.items():
            view_count_dist[len(video_info['views'])] += 1
            pattern_dist[video_info['gait_pattern']] += 1

        print(f"\nğŸ“Š ë‹¤ì¤‘ ë·° í†µê³„:")
        for view_count, count in sorted(view_count_dist.items()):
            print(f"   {view_count}ê°œ ë·°: {count}ê°œ ë¹„ë””ì˜¤")

        print(f"\nğŸ¦´ íŒ¨í„´ë³„ ë¶„í¬:")
        for pattern, count in pattern_dist.items():
            print(f"   {pattern}: {count}ê°œ")

        return self.multi_view_videos

    def scan_multi_view_videos(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ì„ ì§ì ‘ ìŠ¤ìº”í•˜ì—¬ ë‹¤ì¤‘ ë·° ì°¾ê¸°"""
        video_files = list(self.videos_path.glob("*.mp4"))
        video_groups = defaultdict(list)

        # ë¹„ë””ì˜¤ IDë³„ë¡œ ê·¸ë£¹í™”
        for video_file in video_files:
            filename = video_file.stem
            parts = filename.split('_')

            if len(parts) >= 3:
                video_id = parts[0]
                view = '_'.join(parts[1:-1])
                frame_range = parts[-1]

                video_groups[video_id].append({
                    'view': view,
                    'file': str(video_file),
                    'frame_range': frame_range
                })

        # ë‹¤ì¤‘ ë·°ë§Œ í•„í„°ë§
        for video_id, files in video_groups.items():
            if len(files) > 1:
                views = [f['view'] for f in files]
                video_files_dict = {f['view']: f['file'] for f in files}

                self.multi_view_videos[video_id] = {
                    'views': views,
                    'gait_pattern': 'unknown',
                    'dataset_type': 'Unknown',
                    'video_files': video_files_dict
                }

    def extract_view_features(self, video_path, view_type, max_frames=200):
        """íŠ¹ì • ë·°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        features = {
            'success': False,
            'view_type': view_type,
            'frame_count': 0,
            'landmarks': [],
            'joint_angles': [],
            'view_specific_features': {},
            'error_message': None
        }

        try:
            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                features['error_message'] = f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
                return features

            with self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=1,
                enable_segmentation=False,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            ) as pose:

                frame_idx = 0

                while frame_idx < max_frames:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    # BGRì„ RGBë¡œ ë³€í™˜
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose.process(rgb_frame)

                    if results.pose_landmarks:
                        # ëœë“œë§ˆí¬ ì¶”ì¶œ
                        landmarks = []
                        for landmark in results.pose_landmarks.landmark:
                            landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])

                        features['landmarks'].append(landmarks)

                        # ë·°ë³„ íŠ¹ì§• ê³„ì‚°
                        view_features = self.compute_view_specific_features(
                            results.pose_landmarks.landmark, view_type
                        )
                        features['joint_angles'].append(view_features)

                    frame_idx += 1

                cap.release()

                features['frame_count'] = frame_idx
                features['success'] = len(features['landmarks']) > 0

                # ë·°ë³„ íŠ¹í™” íŠ¹ì§• ê³„ì‚°
                if features['success']:
                    features['view_specific_features'] = self.analyze_view_specific_patterns(
                        features['landmarks'], features['joint_angles'], view_type
                    )

        except Exception as e:
            features['error_message'] = str(e)

        return features

    def compute_view_specific_features(self, landmarks, view_type):
        """ë·°ë³„ íŠ¹í™” íŠ¹ì§• ê³„ì‚°"""
        # MediaPipe ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        LEFT_HIP = 23
        RIGHT_HIP = 24
        LEFT_KNEE = 25
        RIGHT_KNEE = 26
        LEFT_ANKLE = 27
        RIGHT_ANKLE = 28

        features = {}

        try:
            if view_type in ['front', 'back']:
                # ì •ë©´/í›„ë©´ ë·°: ì¢Œìš° ëŒ€ì¹­ì„±, ê· í˜• ë¶„ì„
                left_hip = landmarks[LEFT_HIP]
                right_hip = landmarks[RIGHT_HIP]
                left_knee = landmarks[LEFT_KNEE]
                right_knee = landmarks[RIGHT_KNEE]
                left_ankle = landmarks[LEFT_ANKLE]
                right_ankle = landmarks[RIGHT_ANKLE]

                # ì¢Œìš° ëŒ€ì¹­ì„±
                hip_symmetry = abs(left_hip.y - right_hip.y)
                knee_symmetry = abs(left_knee.y - right_knee.y)
                ankle_symmetry = abs(left_ankle.y - right_ankle.y)

                features.update({
                    'hip_symmetry': hip_symmetry,
                    'knee_symmetry': knee_symmetry,
                    'ankle_symmetry': ankle_symmetry,
                    'lateral_balance': abs(left_hip.x - right_hip.x)
                })

            elif view_type in ['left_side', 'right_side']:
                # ì¸¡ë©´ ë·°: ê´€ì ˆ ê°ë„, ë³´í–‰ ì£¼ê¸° ë¶„ì„
                hip = landmarks[LEFT_HIP if view_type == 'left_side' else RIGHT_HIP]
                knee = landmarks[LEFT_KNEE if view_type == 'left_side' else RIGHT_KNEE]
                ankle = landmarks[LEFT_ANKLE if view_type == 'left_side' else RIGHT_ANKLE]

                # ë¬´ë¦ ê°ë„ ê³„ì‚°
                knee_angle = self.calculate_joint_angle(hip, knee, ankle)

                # ë³´í–‰ ë‹¨ê³„ ì¶”ì • (ë°œëª© ë†’ì´ ê¸°ë°˜)
                gait_phase = self.estimate_gait_phase(ankle.y)

                features.update({
                    'knee_angle': knee_angle,
                    'ankle_height': ankle.y,
                    'gait_phase': gait_phase,
                    'trunk_lean': abs(hip.x - 0.5)  # ëª¸í†µ ê¸°ìš¸ê¸°
                })

        except Exception as e:
            features['calculation_error'] = str(e)

        return features

    def calculate_joint_angle(self, point1, point2, point3):
        """ì„¸ ì ìœ¼ë¡œ ê´€ì ˆ ê°ë„ ê³„ì‚°"""
        try:
            # ë²¡í„° ê³„ì‚°
            v1 = np.array([point1.x - point2.x, point1.y - point2.y])
            v2 = np.array([point3.x - point2.x, point3.y - point2.y])

            # ì½”ì‚¬ì¸ ê°’ ê³„ì‚°
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1.0, 1.0)

            # ê°ë„ ë³€í™˜ (ë¼ë””ì•ˆ -> ë„)
            angle = np.arccos(cos_angle) * 180 / np.pi
            return angle
        except:
            return 0.0

    def estimate_gait_phase(self, ankle_y, threshold=0.1):
        """ë°œëª© ë†’ì´ë¡œ ë³´í–‰ ë‹¨ê³„ ì¶”ì •"""
        # ê°„ë‹¨í•œ ì„ê³„ê°’ ê¸°ë°˜ ë³´í–‰ ë‹¨ê³„ ë¶„ë¥˜
        if ankle_y > 0.8:  # ë†’ì€ ìœ„ì¹˜
            return 'swing_high'
        elif ankle_y > 0.7:
            return 'swing_mid'
        elif ankle_y > 0.6:
            return 'stance'
        else:
            return 'contact'

    def analyze_view_specific_patterns(self, landmarks_sequence, joint_angles_sequence, view_type):
        """ë·°ë³„ íŠ¹í™” íŒ¨í„´ ë¶„ì„"""
        if not landmarks_sequence or not joint_angles_sequence:
            return {}

        patterns = {}

        try:
            # ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ë¶„ì„
            if view_type in ['left_side', 'right_side']:
                # ì¸¡ë©´ ë·°: ë³´í–‰ ì£¼ê¸° ë¶„ì„
                ankle_heights = []
                knee_angles = []

                for angles in joint_angles_sequence:
                    if 'ankle_height' in angles:
                        ankle_heights.append(angles['ankle_height'])
                    if 'knee_angle' in angles:
                        knee_angles.append(angles['knee_angle'])

                if ankle_heights:
                    patterns['ankle_height_range'] = max(ankle_heights) - min(ankle_heights)
                    patterns['ankle_height_std'] = np.std(ankle_heights)

                if knee_angles:
                    patterns['knee_angle_range'] = max(knee_angles) - min(knee_angles)
                    patterns['knee_angle_mean'] = np.mean(knee_angles)

            elif view_type in ['front', 'back']:
                # ì •ë©´/í›„ë©´ ë·°: ëŒ€ì¹­ì„± ë³€í™” ë¶„ì„
                symmetry_scores = []

                for angles in joint_angles_sequence:
                    if 'hip_symmetry' in angles and 'knee_symmetry' in angles:
                        symmetry_score = 1.0 - (angles['hip_symmetry'] + angles['knee_symmetry']) / 2
                        symmetry_scores.append(symmetry_score)

                if symmetry_scores:
                    patterns['symmetry_mean'] = np.mean(symmetry_scores)
                    patterns['symmetry_std'] = np.std(symmetry_scores)

        except Exception as e:
            patterns['analysis_error'] = str(e)

        return patterns

    def integrate_multi_view_features(self, video_id):
        """ë‹¤ì¤‘ ë·° íŠ¹ì§• í†µí•©"""
        if video_id not in self.multi_view_videos:
            return None

        video_info = self.multi_view_videos[video_id]
        views = video_info['views']
        video_files = video_info['video_files']

        print(f"ğŸ¬ {video_id} ë‹¤ì¤‘ ë·° íŠ¹ì§• í†µí•© ì¤‘... ({len(views)}ê°œ ë·°)")

        # ê° ë·°ë³„ íŠ¹ì§• ì¶”ì¶œ
        view_results = {}

        for view in views:
            if view in video_files:
                video_path = video_files[view]
                print(f"   ğŸ“¹ {view} ë·° ì²˜ë¦¬...")

                features = self.extract_view_features(video_path, view)
                view_results[view] = features

                if features['success']:
                    print(f"      âœ… {features['frame_count']}í”„ë ˆì„ ì²˜ë¦¬ ì„±ê³µ")
                else:
                    print(f"      âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {features.get('error_message', 'Unknown error')}")

        # ë·° í†µí•© ì•Œê³ ë¦¬ì¦˜
        integrated_features = self.fuse_multi_view_features(view_results, video_info)

        self.integrated_features[video_id] = {
            'video_info': video_info,
            'view_results': view_results,
            'integrated_features': integrated_features,
            'processing_timestamp': datetime.now().isoformat()
        }

        return self.integrated_features[video_id]

    def fuse_multi_view_features(self, view_results, video_info):
        """ë‹¤ì¤‘ ë·° íŠ¹ì§• ìœµí•©"""
        fused_features = {
            'gait_symmetry': 0.0,
            'gait_stability': 0.0,
            'joint_coordination': 0.0,
            'movement_fluidity': 0.0,
            'pathological_indicators': {},
            'confidence_score': 0.0,
            'view_contributions': {}
        }

        successful_views = {view: result for view, result in view_results.items() if result['success']}

        if not successful_views:
            return fused_features

        # ê°€ì¤‘ í‰ê·  ê¸°ë°˜ íŠ¹ì§• ìœµí•©
        total_weight = 0
        weighted_features = defaultdict(float)

        for view, result in successful_views.items():
            view_weight = self.camera_views.get(view, {}).get('weight', 1.0)
            total_weight += view_weight

            # ë·°ë³„ íŠ¹í™” íŠ¹ì§• ì¶”ì¶œ
            view_specific = result.get('view_specific_features', {})

            if view in ['front', 'back']:
                # ì •ë©´/í›„ë©´: ëŒ€ì¹­ì„± ì •ë³´
                if 'symmetry_mean' in view_specific:
                    weighted_features['symmetry'] += view_specific['symmetry_mean'] * view_weight

            elif view in ['left_side', 'right_side']:
                # ì¸¡ë©´: ê´€ì ˆ ê°ë„ ë° ë³´í–‰ ì£¼ê¸° ì •ë³´
                if 'knee_angle_mean' in view_specific:
                    weighted_features['knee_angle'] += view_specific['knee_angle_mean'] * view_weight
                if 'ankle_height_range' in view_specific:
                    weighted_features['ankle_range'] += view_specific['ankle_height_range'] * view_weight

            # ë·° ê¸°ì—¬ë„ ê¸°ë¡
            fused_features['view_contributions'][view] = {
                'weight': view_weight,
                'frame_count': result['frame_count'],
                'features_extracted': len(view_specific)
            }

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        if total_weight > 0:
            for feature, value in weighted_features.items():
                weighted_features[feature] = value / total_weight

        # ìµœì¢… íŠ¹ì§• ê³„ì‚°
        fused_features['gait_symmetry'] = weighted_features.get('symmetry', 0.5)
        fused_features['joint_coordination'] = np.mean([
            weighted_features.get('knee_angle', 45) / 90,  # ì •ê·œí™”
            weighted_features.get('ankle_range', 0.1) * 10   # ì •ê·œí™”
        ])

        # ì•ˆì •ì„± ë° ìœ ë™ì„± ê³„ì‚°
        fused_features['gait_stability'] = 1.0 - np.std([
            result.get('view_specific_features', {}).get('ankle_height_std', 0.1)
            for result in successful_views.values()
        ])

        fused_features['movement_fluidity'] = min(1.0, np.mean([
            len(result['landmarks']) / max(result['frame_count'], 1)
            for result in successful_views.values()
        ]))

        # ë³‘ì  ì§€í‘œ ê³„ì‚°
        pathological_score = 0.0

        if fused_features['gait_symmetry'] < 0.7:
            pathological_score += 0.3
        if fused_features['joint_coordination'] < 0.6:
            pathological_score += 0.25
        if fused_features['gait_stability'] < 0.5:
            pathological_score += 0.25
        if fused_features['movement_fluidity'] < 0.7:
            pathological_score += 0.2

        fused_features['pathological_indicators'] = {
            'overall_score': pathological_score,
            'risk_level': 'high' if pathological_score > 0.6 else 'medium' if pathological_score > 0.3 else 'low'
        }

        # ì‹ ë¢°ë„ ì ìˆ˜ (ì‚¬ìš©ëœ ë·° ìˆ˜ì™€ ì„±ê³µë¥  ê¸°ë°˜)
        fused_features['confidence_score'] = min(1.0, len(successful_views) / 4.0 * 0.8 +
                                                 fused_features['movement_fluidity'] * 0.2)

        return fused_features

    def process_multi_view_batch(self, limit_videos=10):
        """ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ë°°ì¹˜ ì²˜ë¦¬"""
        print(f"\nğŸš€ ë‹¤ì¤‘ ë·° ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)

        if not self.multi_view_videos:
            self.load_multi_view_data()

        # ì²˜ë¦¬í•  ë¹„ë””ì˜¤ ì„ íƒ
        video_ids = list(self.multi_view_videos.keys())[:limit_videos]

        print(f"ğŸ¬ {len(video_ids)}ê°œ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜ˆì •")

        results = []

        for i, video_id in enumerate(video_ids, 1):
            print(f"\nğŸ“¹ [{i}/{len(video_ids)}] {video_id} ì²˜ë¦¬ ì¤‘...")

            try:
                result = self.integrate_multi_view_features(video_id)
                if result:
                    results.append(result)
                    print(f"   âœ… í†µí•© ì™„ë£Œ")
                else:
                    print(f"   âŒ í†µí•© ì‹¤íŒ¨")

            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜: {e}")

        print(f"\nğŸ‰ ë‹¤ì¤‘ ë·° ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {len(results)}/{len(video_ids)}ê°œ")

        return results

    def analyze_multi_view_performance(self):
        """ë‹¤ì¤‘ ë·° ì„±ëŠ¥ ë¶„ì„"""
        if not self.integrated_features:
            print("âŒ í†µí•©ëœ íŠ¹ì§•ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        print(f"\nğŸ“Š ë‹¤ì¤‘ ë·° ì„±ëŠ¥ ë¶„ì„...")

        analysis = {
            'total_videos': len(self.integrated_features),
            'view_coverage': defaultdict(int),
            'performance_metrics': {},
            'pathological_detection': {'high': 0, 'medium': 0, 'low': 0}
        }

        # ë·° ì»¤ë²„ë¦¬ì§€ ë¶„ì„
        for video_id, result in self.integrated_features.items():
            view_results = result['view_results']
            successful_views = [view for view, res in view_results.items() if res['success']]

            for view in successful_views:
                analysis['view_coverage'][view] += 1

            # ë³‘ì  ìœ„í—˜ë„ ë¶„ì„
            integrated = result['integrated_features']
            risk_level = integrated.get('pathological_indicators', {}).get('risk_level', 'low')
            analysis['pathological_detection'][risk_level] += 1

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        confidence_scores = []
        symmetry_scores = []
        stability_scores = []

        for result in self.integrated_features.values():
            integrated = result['integrated_features']
            confidence_scores.append(integrated.get('confidence_score', 0))
            symmetry_scores.append(integrated.get('gait_symmetry', 0))
            stability_scores.append(integrated.get('gait_stability', 0))

        analysis['performance_metrics'] = {
            'average_confidence': np.mean(confidence_scores),
            'average_symmetry': np.mean(symmetry_scores),
            'average_stability': np.mean(stability_scores),
            'high_confidence_ratio': sum(1 for s in confidence_scores if s > 0.8) / len(confidence_scores)
        }

        print(f"ğŸ“ˆ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì´ ë¹„ë””ì˜¤: {analysis['total_videos']}")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {analysis['performance_metrics']['average_confidence']:.3f}")
        print(f"   í‰ê·  ëŒ€ì¹­ì„±: {analysis['performance_metrics']['average_symmetry']:.3f}")
        print(f"   í‰ê·  ì•ˆì •ì„±: {analysis['performance_metrics']['average_stability']:.3f}")

        print(f"\nğŸ¥ ë·°ë³„ ì»¤ë²„ë¦¬ì§€:")
        for view, count in analysis['view_coverage'].items():
            percentage = count / analysis['total_videos'] * 100
            print(f"   {view}: {count}ê°œ ({percentage:.1f}%)")

        print(f"\nğŸ¦´ ìœ„í—˜ë„ ë¶„í¬:")
        for risk, count in analysis['pathological_detection'].items():
            percentage = count / analysis['total_videos'] * 100
            print(f"   {risk}: {count}ê°œ ({percentage:.1f}%)")

        return analysis

    def save_multi_view_results(self, output_file=None):
        """ë‹¤ì¤‘ ë·° ê²°ê³¼ ì €ì¥"""
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f"gavd_multiview_results_{timestamp}.json"

        # ì„±ëŠ¥ ë¶„ì„
        performance_analysis = self.analyze_multi_view_performance()

        # ì „ì²´ ê²°ê³¼ êµ¬ì¡°
        full_results = {
            'processing_info': {
                'timestamp': datetime.now().isoformat(),
                'total_multi_view_videos': len(self.multi_view_videos),
                'processed_videos': len(self.integrated_features),
                'camera_views_supported': list(self.camera_views.keys())
            },
            'performance_analysis': performance_analysis,
            'integrated_features': self.integrated_features,
            'multi_view_videos_info': self.multi_view_videos
        }

        # JSON ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(full_results, f, indent=2, ensure_ascii=False)

        file_size = Path(output_file).stat().st_size / (1024*1024)  # MB
        print(f"\nğŸ’¾ ë‹¤ì¤‘ ë·° ê²°ê³¼ ì €ì¥: {output_file}")
        print(f"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB")

        return output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¥ GAVD ë‹¤ì¤‘ ë·° ë³´í–‰ ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ")
    print("=" * 60)

    # ê¸°ì¡´ GAVD ë¶„ì„ íŒŒì¼ ì°¾ê¸°
    gavd_analysis_files = list(Path(".").glob("gavd_dataset_analysis_*.json"))
    gavd_file = gavd_analysis_files[0] if gavd_analysis_files else None

    # ë‹¤ì¤‘ ë·° ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = GAVDMultiViewGaitAnalyzer(gavd_analysis_file=gavd_file)

    try:
        # 1. ë‹¤ì¤‘ ë·° ë°ì´í„° ë¡œë“œ
        analyzer.load_multi_view_data()

        # 2. ë‹¤ì¤‘ ë·° ë°°ì¹˜ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸: 5ê°œ ë¹„ë””ì˜¤)
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 5ê°œ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì²˜ë¦¬")
        results = analyzer.process_multi_view_batch(limit_videos=5)

        # 3. ì„±ëŠ¥ ë¶„ì„
        analysis = analyzer.analyze_multi_view_performance()

        # 4. ê²°ê³¼ ì €ì¥
        output_file = analyzer.save_multi_view_results()

        print(f"\nğŸ‰ GAVD ë‹¤ì¤‘ ë·° ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
        print(f"ğŸ¬ {len(results)}ê°œ ë¹„ë””ì˜¤ ì„±ê³µì  ì²˜ë¦¬")

        if analysis['performance_metrics']['average_confidence'] > 0.7:
            print(f"\nâœ¨ í‰ê·  ì‹ ë¢°ë„ {analysis['performance_metrics']['average_confidence']:.1%}ë¡œ ë†’ìŠµë‹ˆë‹¤!")
            print(f"ğŸ’¡ ì „ì²´ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ë‹¤ì¤‘ ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()