#!/usr/bin/env python3
"""
GAVD Dataset Analyzer
Enhanced MediaPipe Gait Analysis System v2.0 - GAVD Integration

ì‹¤ì œ ì„ìƒ ë°ì´í„°ë¥¼ í™œìš©í•œ ë³‘ì ë³´í–‰ ê²€ì¶œ ì‹œìŠ¤í…œ ê°œë°œì„ ìœ„í•œ GAVD ë°ì´í„°ì…‹ ë¶„ì„ê¸°

Author: Research Team
Date: 2025-09-22
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
import ast
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

class GAVDDatasetAnalyzer:
    """GAVD ë°ì´í„°ì…‹ ë¶„ì„ ë° ì„ìƒ ì£¼ì„ ì¶”ì¶œê¸°"""

    def __init__(self, gavd_path="/data/datasets/GAVD"):
        """
        GAVD ë°ì´í„°ì…‹ ì´ˆê¸°í™”

        Args:
            gavd_path: GAVD ë°ì´í„°ì…‹ ê²½ë¡œ
        """
        self.gavd_path = Path(gavd_path)
        self.data_path = self.gavd_path / "data"
        self.videos_path = self.gavd_path / "videos_cut_by_view"

        # ì„ìƒ ì£¼ì„ íŒŒì¼ë“¤
        self.annotation_files = list(self.data_path.glob("GAVD_Clinical_Annotations_*.csv"))

        # í†µí•© ë°ì´í„°í”„ë ˆì„
        self.combined_annotations = None
        self.pathological_patterns = {}
        self.camera_views = {}
        self.gait_analysis_summary = {}

        print(f"ğŸ” GAVD Dataset Analyzer ì´ˆê¸°í™”")
        print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {self.gavd_path}")
        print(f"ğŸ“Š ì£¼ì„ íŒŒì¼ ìˆ˜: {len(self.annotation_files)}")
        print(f"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ìˆ˜: {len(list(self.videos_path.glob('*.mp4')))}")

    def load_clinical_annotations(self):
        """ëª¨ë“  ì„ìƒ ì£¼ì„ íŒŒì¼ ë¡œë“œ ë° í†µí•©"""
        print(f"\nğŸ“– ì„ìƒ ì£¼ì„ ë°ì´í„° ë¡œë“œ ì¤‘...")

        all_annotations = []

        for i, file_path in enumerate(self.annotation_files, 1):
            print(f"   {i}/5: {file_path.name}")

            try:
                df = pd.read_csv(file_path)
                all_annotations.append(df)
                print(f"      âœ… {len(df):,}ê°œ í–‰ ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {e}")

        # ëª¨ë“  ë°ì´í„° í†µí•©
        self.combined_annotations = pd.concat(all_annotations, ignore_index=True)

        print(f"\nğŸ“Š í†µí•© ì™„ë£Œ:")
        print(f"   ì´ ë°ì´í„° í–‰ ìˆ˜: {len(self.combined_annotations):,}")
        print(f"   ê³ ìœ  ì‹œí€€ìŠ¤ ID: {self.combined_annotations['seq'].nunique()}")
        print(f"   ê³ ìœ  ë¹„ë””ì˜¤ ID: {self.combined_annotations['id'].nunique()}")

        return self.combined_annotations

    def analyze_pathological_patterns(self):
        """ë³‘ì ë³´í–‰ íŒ¨í„´ ë¶„ì„"""
        if self.combined_annotations is None:
            self.load_clinical_annotations()

        print(f"\nğŸ¦´ ë³‘ì ë³´í–‰ íŒ¨í„´ ë¶„ì„...")

        # ê¸°ë³¸ ë¶„í¬ ë¶„ì„
        gait_pattern_dist = self.combined_annotations['gait_pat'].value_counts()
        dataset_type_dist = self.combined_annotations['dataset'].value_counts()

        print(f"\nğŸ“ˆ ë³´í–‰ íŒ¨í„´ ë¶„í¬:")
        for pattern, count in gait_pattern_dist.items():
            percentage = (count / len(self.combined_annotations)) * 100
            print(f"   {pattern}: {count:,}ê°œ ({percentage:.1f}%)")

        print(f"\nğŸ“‹ ë°ì´í„°ì…‹ ìœ í˜• ë¶„í¬:")
        for dataset_type, count in dataset_type_dist.items():
            percentage = (count / len(self.combined_annotations)) * 100
            print(f"   {dataset_type}: {count:,}ê°œ ({percentage:.1f}%)")

        # ê³ ìœ  ë¹„ë””ì˜¤ë³„ ë³‘ì ë³´í–‰ íŒ¨í„´
        unique_videos = self.combined_annotations.groupby('id').agg({
            'gait_pat': 'first',
            'dataset': 'first',
            'cam_view': lambda x: list(set(x)),
            'seq': 'nunique'
        }).reset_index()

        print(f"\nğŸ¬ ê³ ìœ  ë¹„ë””ì˜¤ ë¶„ì„:")
        print(f"   ì´ ê³ ìœ  ë¹„ë””ì˜¤: {len(unique_videos)}")

        video_pattern_dist = unique_videos['gait_pat'].value_counts()
        print(f"\nğŸ“Š ë¹„ë””ì˜¤ë³„ ë³´í–‰ íŒ¨í„´:")
        for pattern, count in video_pattern_dist.items():
            percentage = (count / len(unique_videos)) * 100
            print(f"   {pattern}: {count}ê°œ ë¹„ë””ì˜¤ ({percentage:.1f}%)")

        # ì¹´ë©”ë¼ ë·° ë¶„ì„
        all_views = []
        for views in unique_videos['cam_view']:
            all_views.extend(views)

        view_dist = Counter(all_views)
        print(f"\nğŸ“· ì¹´ë©”ë¼ ë·° ë¶„í¬:")
        for view, count in view_dist.most_common():
            percentage = (count / len(unique_videos)) * 100
            print(f"   {view}: {count}ê°œ ë¹„ë””ì˜¤ ({percentage:.1f}%)")

        # ë³‘ì ë³´í–‰ íŒ¨í„´ë³„ ìƒì„¸ ë¶„ì„
        self.pathological_patterns = {
            'pattern_distribution': gait_pattern_dist.to_dict(),
            'dataset_distribution': dataset_type_dist.to_dict(),
            'unique_videos': unique_videos.to_dict('records'),
            'video_pattern_distribution': video_pattern_dist.to_dict(),
            'camera_view_distribution': dict(view_dist)
        }

        return self.pathological_patterns

    def analyze_camera_views(self):
        """ë‹¤ì¤‘ ì¹´ë©”ë¼ ë·° ë¶„ì„"""
        if self.combined_annotations is None:
            self.load_clinical_annotations()

        print(f"\nğŸ“· ë‹¤ì¤‘ ì¹´ë©”ë¼ ë·° ë¶„ì„...")

        # ì¹´ë©”ë¼ ë·°ë³„ ë°ì´í„° ë¶„í¬
        view_analysis = self.combined_annotations.groupby(['cam_view', 'gait_pat']).size().unstack(fill_value=0)

        print(f"\nğŸ“Š ì¹´ë©”ë¼ ë·°ë³„ ë³´í–‰ íŒ¨í„´ ë¶„í¬:")
        print(view_analysis)

        # ë‹¤ì¤‘ ë·°ë¥¼ ê°€ì§„ ë¹„ë””ì˜¤ ì°¾ê¸°
        multi_view_videos = self.combined_annotations.groupby('id')['cam_view'].nunique()
        multi_view_videos = multi_view_videos[multi_view_videos > 1]

        print(f"\nğŸ¥ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ë¶„ì„:")
        print(f"   ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ìˆ˜: {len(multi_view_videos)}")
        print(f"   ë‹¨ì¼ ë·° ë¹„ë””ì˜¤ ìˆ˜: {self.combined_annotations['id'].nunique() - len(multi_view_videos)}")

        # ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´
        if len(multi_view_videos) > 0:
            print(f"\nğŸ“‹ ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ):")
            for i, (video_id, view_count) in enumerate(multi_view_videos.head(10).items()):
                views = self.combined_annotations[self.combined_annotations['id'] == video_id]['cam_view'].unique()
                # NaN ê°’ ì²˜ë¦¬
                views = [str(view) for view in views if pd.notna(view)]
                gait_pattern = self.combined_annotations[self.combined_annotations['id'] == video_id]['gait_pat'].iloc[0]
                print(f"   {i+1}. {video_id}: {view_count}ê°œ ë·° ({', '.join(views)}) - {gait_pattern}")

        self.camera_views = {
            'view_pattern_matrix': view_analysis.to_dict(),
            'multi_view_videos': multi_view_videos.to_dict(),
            'multi_view_count': len(multi_view_videos),
            'single_view_count': self.combined_annotations['id'].nunique() - len(multi_view_videos)
        }

        return self.camera_views

    def match_videos_with_annotations(self, side_view_only=True):
        """ë¹„ë””ì˜¤ íŒŒì¼ê³¼ ì„ìƒ ì£¼ì„ ë§¤ì¹­ (side view ì „ìš© ì˜µì…˜)"""
        print(f"\nğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ê³¼ ì„ìƒ ì£¼ì„ ë§¤ì¹­...")
        if side_view_only:
            print(f"   ğŸ“ Side view ì „ìš© ëª¨ë“œ í™œì„±í™”")

        # ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡
        video_files = list(self.videos_path.glob("*.mp4"))

        # Side view í•„í„°ë§
        if side_view_only:
            side_view_files = []
            for video_file in video_files:
                filename = video_file.stem
                parts = filename.split('_')
                if len(parts) >= 3:
                    view = '_'.join(parts[1:-1])
                    if view in ['left_side', 'right_side']:
                        side_view_files.append(video_file)
            video_files = side_view_files
            print(f"   ğŸ“ Side view í•„í„°ë§ í›„: {len(video_files)}ê°œ")

        video_file_names = [f.stem for f in video_files]
        print(f"   ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼: {len(video_files)}ê°œ")

        # ì£¼ì„ì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ
        annotated_video_ids = set(self.combined_annotations['id'].unique())
        print(f"   ì£¼ì„ ë°ì´í„° ë¹„ë””ì˜¤ ID: {len(annotated_video_ids)}ê°œ")

        # íŒŒì¼ëª…ì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ (íŒŒì¼ëª… íŒ¨í„´: {video_id}_{view}_{frame_range}.mp4)
        extracted_ids = set()
        for filename in video_file_names:
            parts = filename.split('_')
            if len(parts) >= 3:
                video_id = parts[0]
                extracted_ids.add(video_id)

        print(f"   íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œëœ ë¹„ë””ì˜¤ ID: {len(extracted_ids)}ê°œ")

        # ë§¤ì¹­ ë¶„ì„
        matched_ids = annotated_video_ids.intersection(extracted_ids)
        unmatched_annotations = annotated_video_ids - extracted_ids
        unmatched_files = extracted_ids - annotated_video_ids

        print(f"\nğŸ“Š ë§¤ì¹­ ê²°ê³¼:")
        print(f"   ë§¤ì¹­ëœ ë¹„ë””ì˜¤ ID: {len(matched_ids)}ê°œ")
        print(f"   ì£¼ì„ë§Œ ìˆëŠ” ID: {len(unmatched_annotations)}ê°œ")
        print(f"   íŒŒì¼ë§Œ ìˆëŠ” ID: {len(unmatched_files)}ê°œ")

        # ë§¤ì¹­ëœ ë¹„ë””ì˜¤ì˜ ë³‘ì ë³´í–‰ íŒ¨í„´ ë¶„ì„
        matched_annotations = self.combined_annotations[
            self.combined_annotations['id'].isin(matched_ids)
        ]

        matched_pattern_dist = matched_annotations.groupby('id')['gait_pat'].first().value_counts()
        print(f"\nğŸ¦´ ë§¤ì¹­ëœ ë¹„ë””ì˜¤ì˜ ë³‘ì ë³´í–‰ íŒ¨í„´:")
        for pattern, count in matched_pattern_dist.items():
            percentage = (count / len(matched_ids)) * 100
            print(f"   {pattern}: {count}ê°œ ({percentage:.1f}%)")

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤-ì£¼ì„ ìŒ ìƒì„±
        available_pairs = []

        for video_file in video_files:
            filename = video_file.stem
            parts = filename.split('_')

            if len(parts) >= 3:
                video_id = parts[0]
                view = '_'.join(parts[1:-1])  # viewê°€ 'left_side' ê°™ì´ ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨í•  ìˆ˜ ìˆìŒ
                frame_range = parts[-1]

                if video_id in annotated_video_ids:
                    # ì¹´ë©”ë¼ ë·° í‘œê¸° í†µì¼ (íŒŒì¼ëª…: left_side <-> ì£¼ì„: left side)
                    normalized_view = view.replace('_', ' ')

                    # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ì£¼ì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    video_annotations = self.combined_annotations[
                        (self.combined_annotations['id'] == video_id) &
                        (self.combined_annotations['cam_view'] == normalized_view)
                    ]

                    if not video_annotations.empty:
                        gait_pattern = video_annotations['gait_pat'].iloc[0]
                        dataset_type = video_annotations['dataset'].iloc[0]

                        available_pairs.append({
                            'video_file': str(video_file),
                            'video_id': video_id,
                            'camera_view': view,
                            'frame_range': frame_range,
                            'gait_pattern': gait_pattern,
                            'dataset_type': dataset_type,
                            'annotation_count': len(video_annotations)
                        })

        print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤-ì£¼ì„ ìŒ: {len(available_pairs)}ê°œ")

        # íŒ¨í„´ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ìˆ˜
        pattern_counts = Counter([pair['gait_pattern'] for pair in available_pairs])
        print(f"\nğŸ“ˆ íŒ¨í„´ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ ìˆ˜:")
        for pattern, count in pattern_counts.most_common():
            percentage = (count / len(available_pairs)) * 100
            print(f"   {pattern}: {count}ê°œ ({percentage:.1f}%)")

        # ì¹´ë©”ë¼ ë·° ë¶„í¬ (side view onlyì¼ ë•Œ)
        if side_view_only and available_pairs:
            view_counts = Counter([pair['camera_view'] for pair in available_pairs])
            print(f"\nğŸ“· Side view ë¶„í¬:")
            for view, count in view_counts.most_common():
                print(f"   {view}: {count}ê°œ")

        return available_pairs

    def generate_dataset_summary(self):
        """GAVD ë°ì´í„°ì…‹ ì¢…í•© ìš”ì•½ ìƒì„±"""
        print(f"\nğŸ“‹ GAVD ë°ì´í„°ì…‹ ì¢…í•© ìš”ì•½ ìƒì„±...")

        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        if self.combined_annotations is None:
            self.load_clinical_annotations()

        if not self.pathological_patterns:
            self.analyze_pathological_patterns()

        if not self.camera_views:
            self.analyze_camera_views()

        available_pairs = self.match_videos_with_annotations()

        # ì¢…í•© ìš”ì•½ ìƒì„±
        summary = {
            'dataset_info': {
                'total_annotation_rows': len(self.combined_annotations),
                'unique_video_ids': self.combined_annotations['id'].nunique(),
                'unique_sequences': self.combined_annotations['seq'].nunique(),
                'total_video_files': len(list(self.videos_path.glob("*.mp4"))),
                'available_video_annotation_pairs': len(available_pairs)
            },
            'pathological_patterns': self.pathological_patterns,
            'camera_views': self.camera_views,
            'clinical_applications': {
                'parkinsons_videos': len([p for p in available_pairs if p['gait_pattern'] == 'parkinsons']),
                'normal_videos': len([p for p in available_pairs if p['dataset_type'] == 'Normal Gait']),
                'abnormal_videos': len([p for p in available_pairs if p['dataset_type'] == 'Abnormal Gait']),
                'multi_view_potential': self.camera_views['multi_view_count']
            },
            'technical_specs': {
                'video_format': 'MP4',
                'annotation_format': 'CSV',
                'bounding_box_available': True,
                'frame_level_annotations': True,
                'clinical_labels': True
            },
            'analysis_timestamp': datetime.now().isoformat(),
            'available_pairs_sample': available_pairs[:10]  # ìƒ˜í”Œ 10ê°œ
        }

        self.gait_analysis_summary = summary

        # ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ¯ GAVD ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ!")
        print(f"=" * 60)
        print(f"ğŸ“Š ê¸°ë³¸ í†µê³„:")
        print(f"   ì´ ì£¼ì„ ë°ì´í„°: {summary['dataset_info']['total_annotation_rows']:,}í–‰")
        print(f"   ê³ ìœ  ë¹„ë””ì˜¤ ID: {summary['dataset_info']['unique_video_ids']}ê°œ")
        print(f"   ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼: {summary['dataset_info']['total_video_files']}ê°œ")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤-ì£¼ì„ ìŒ: {summary['dataset_info']['available_video_annotation_pairs']}ê°œ")

        print(f"\nğŸ¦´ ì„ìƒ í™œìš© ê°€ëŠ¥ì„±:")
        print(f"   íŒŒí‚¨ìŠ¨ë³‘ ë¹„ë””ì˜¤: {summary['clinical_applications']['parkinsons_videos']}ê°œ")
        print(f"   ì •ìƒ ë³´í–‰ ë¹„ë””ì˜¤: {summary['clinical_applications']['normal_videos']}ê°œ")
        print(f"   ë¹„ì •ìƒ ë³´í–‰ ë¹„ë””ì˜¤: {summary['clinical_applications']['abnormal_videos']}ê°œ")
        print(f"   ë‹¤ì¤‘ ë·° ë¹„ë””ì˜¤: {summary['clinical_applications']['multi_view_potential']}ê°œ")

        return summary

    def save_analysis_results(self, output_file="gavd_dataset_analysis.json"):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if not self.gait_analysis_summary:
            self.generate_dataset_summary()

        output_path = Path(output_file)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.gait_analysis_summary, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {output_path.stat().st_size / 1024:.1f} KB")

        return output_path

    def create_visualization(self, save_path="gavd_dataset_visualization.png"):
        """ë°ì´í„°ì…‹ ë¶„ì„ ì‹œê°í™”"""
        if not self.pathological_patterns:
            self.analyze_pathological_patterns()

        # ì‹œê°í™” ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('GAVD Dataset Analysis Visualization', fontsize=16, fontweight='bold')

        # 1. ë³´í–‰ íŒ¨í„´ ë¶„í¬
        pattern_data = self.pathological_patterns['video_pattern_distribution']
        axes[0, 0].pie(pattern_data.values(), labels=pattern_data.keys(), autopct='%1.1f%%')
        axes[0, 0].set_title('Gait Pattern Distribution')

        # 2. ë°ì´í„°ì…‹ ìœ í˜• ë¶„í¬
        dataset_data = self.pathological_patterns['dataset_distribution']
        axes[0, 1].bar(dataset_data.keys(), dataset_data.values())
        axes[0, 1].set_title('Dataset Type Distribution')
        axes[0, 1].tick_params(axis='x', rotation=45)

        # 3. ì¹´ë©”ë¼ ë·° ë¶„í¬
        view_data = self.pathological_patterns.get('camera_view_distribution', {})
        if view_data:
            # NaN ê°’ ì œê±°
            clean_view_data = {k: v for k, v in view_data.items() if pd.notna(k) and k != 'nan'}
            if clean_view_data:
                axes[1, 0].bar(clean_view_data.keys(), clean_view_data.values())
                axes[1, 0].set_title('Camera View Distribution')
                axes[1, 0].tick_params(axis='x', rotation=45)

        # 4. ì‹œê°„ë³„ í”„ë ˆì„ ë¶„í¬ (ìƒ˜í”Œ)
        if self.combined_annotations is not None:
            frame_counts = self.combined_annotations.groupby('id')['frame_num'].count()
            axes[1, 1].hist(frame_counts, bins=20, alpha=0.7)
            axes[1, 1].set_title('Frames per Video Distribution')
            axes[1, 1].set_xlabel('Number of Frames')
            axes[1, 1].set_ylabel('Number of Videos')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“Š ì‹œê°í™” ì €ì¥: {save_path}")

        return save_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” GAVD ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘")
    print("=" * 60)

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = GAVDDatasetAnalyzer()

    try:
        # 1. ì„ìƒ ì£¼ì„ ë¡œë“œ
        analyzer.load_clinical_annotations()

        # 2. ë³‘ì ë³´í–‰ íŒ¨í„´ ë¶„ì„
        analyzer.analyze_pathological_patterns()

        # 3. ì¹´ë©”ë¼ ë·° ë¶„ì„
        analyzer.analyze_camera_views()

        # 4. ì¢…í•© ìš”ì•½ ìƒì„±
        summary = analyzer.generate_dataset_summary()

        # 5. ê²°ê³¼ ì €ì¥
        output_file = f"gavd_dataset_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        analyzer.save_analysis_results(output_file)

        # 6. ì‹œê°í™” ìƒì„±
        viz_file = f"gavd_dataset_visualization_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        analyzer.create_visualization(viz_file)

        print(f"\nğŸ‰ GAVD ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“‹ ìš”ì•½: {len(summary['dataset_info']['available_video_annotation_pairs'])}ê°œ ë¹„ë””ì˜¤-ì£¼ì„ ìŒ ì‚¬ìš© ê°€ëŠ¥")
        print(f"ğŸ¦´ ì„ìƒ ë°ì´í„°: íŒŒí‚¨ìŠ¨ë³‘ {summary['clinical_applications']['parkinsons_videos']}ê°œ, "
              f"ì •ìƒ {summary['clinical_applications']['normal_videos']}ê°œ, "
              f"ë¹„ì •ìƒ {summary['clinical_applications']['abnormal_videos']}ê°œ")

    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()