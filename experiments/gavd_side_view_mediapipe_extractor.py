#!/usr/bin/env python3
"""
GAVD Side View MediaPipe Gait Analysis Extractor
Enhanced MediaPipe Gait Analysis System v3.0 - Side View ì „ìš©

ì‹¤ì œ GAVD ì„ìƒ ë™ì˜ìƒ(side view)ì—ì„œ MediaPipeë¥¼ ì‚¬ìš©í•œ ë³´í–‰ ë¶„ì„

Author: Research Team
Date: 2025-09-22
"""

import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import json
from pathlib import Path
import matplotlib.pyplot as plt
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class GAVDSideViewMediaPipeExtractor:
    """GAVD Side View ì „ìš© MediaPipe ë³´í–‰ ë¶„ì„ ì¶”ì¶œê¸°"""

    def __init__(self, gavd_analyzer=None):
        """
        GAVD Side View MediaPipe ì¶”ì¶œê¸° ì´ˆê¸°í™”

        Args:
            gavd_analyzer: GAVDDatasetAnalyzer ì¸ìŠ¤í„´ìŠ¤
        """
        self.gavd_analyzer = gavd_analyzer

        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

        # Side view ì „ìš© ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        self.side_view_landmarks = {
            # í•˜ì²´ ì£¼ìš” ê´€ì ˆ (side viewì—ì„œ ì¤‘ìš”)
            'left_hip': 23,
            'right_hip': 24,
            'left_knee': 25,
            'right_knee': 26,
            'left_ankle': 27,
            'right_ankle': 28,
            'left_heel': 29,
            'right_heel': 30,
            'left_foot_index': 31,
            'right_foot_index': 32,

            # ìƒì²´ (ìì„¸ ì°¸ì¡°ìš©)
            'left_shoulder': 11,
            'right_shoulder': 12,
            'nose': 0
        }

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.side_view_pairs = []
        self.extraction_results = []
        self.processing_stats = {
            'total_videos': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'side_view_only': True
        }

        print(f"ğŸ“ GAVD Side View MediaPipe ì¶”ì¶œê¸° ì´ˆê¸°í™”")
        print(f"ğŸ¥ ì§€ì› ë·°: left_side, right_side")

    def load_side_view_pairs(self):
        """Side view ë¹„ë””ì˜¤-ì£¼ì„ ìŒ ë¡œë“œ"""
        print(f"\nğŸ“ Side view ë¹„ë””ì˜¤-ì£¼ì„ ìŒ ë¡œë“œ ì¤‘...")

        if self.gavd_analyzer is None:
            from gavd_dataset_analyzer import GAVDDatasetAnalyzer
            self.gavd_analyzer = GAVDDatasetAnalyzer()
            self.gavd_analyzer.load_clinical_annotations()

        # Side view ì „ìš© ë§¤ì¹­
        self.side_view_pairs = self.gavd_analyzer.match_videos_with_annotations(side_view_only=True)

        print(f"âœ… Side view ìŒ ë¡œë“œ ì™„ë£Œ: {len(self.side_view_pairs)}ê°œ")

        # ë·°ë³„ ë¶„í¬ í™•ì¸
        view_counts = {}
        for pair in self.side_view_pairs:
            view = pair['camera_view']
            view_counts[view] = view_counts.get(view, 0) + 1

        print(f"ğŸ“· Side view ë¶„í¬:")
        for view, count in view_counts.items():
            print(f"   {view}: {count}ê°œ")

        return self.side_view_pairs

    def extract_pose_landmarks(self, video_path):
        """ë‹¨ì¼ ë¹„ë””ì˜¤ì—ì„œ pose landmarks ì¶”ì¶œ"""
        cap = cv2.VideoCapture(str(video_path))

        if not cap.isOpened():
            return None, "ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨"

        landmarks_sequence = []
        frame_count = 0
        successful_frames = 0

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_count += 1

                # BGRì„ RGBë¡œ ë³€í™˜
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # MediaPipeë¡œ pose ê²€ì¶œ
                results = self.pose.process(rgb_frame)

                if results.pose_landmarks:
                    successful_frames += 1

                    # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
                    landmarks = []
                    for landmark in results.pose_landmarks.landmark:
                        landmarks.append({
                            'x': landmark.x,
                            'y': landmark.y,
                            'z': landmark.z,
                            'visibility': landmark.visibility
                        })

                    landmarks_sequence.append({
                        'frame_number': frame_count,
                        'landmarks': landmarks,
                        'timestamp': frame_count / cap.get(cv2.CAP_PROP_FPS)
                    })

        except Exception as e:
            return None, f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"

        finally:
            cap.release()

        if len(landmarks_sequence) == 0:
            return None, "ìœ íš¨í•œ pose ê²€ì¶œ ì—†ìŒ"

        success_rate = successful_frames / frame_count if frame_count > 0 else 0

        return {
            'landmarks_sequence': landmarks_sequence,
            'total_frames': frame_count,
            'successful_frames': successful_frames,
            'success_rate': success_rate,
            'fps': cap.get(cv2.CAP_PROP_FPS)
        }, "ì„±ê³µ"

    def extract_gait_cycle_features(self, landmarks_data, camera_view):
        """Side view ëœë“œë§ˆí¬ì—ì„œ ë³´í–‰ ì£¼ê¸° íŠ¹ì§• ì¶”ì¶œ"""
        landmarks_sequence = landmarks_data['landmarks_sequence']

        # ë°œëª©ê³¼ ë°œê°€ë½ ê¶¤ì  ì¶”ì¶œ (side view ìµœì í™”)
        ankle_trajectory = []
        heel_trajectory = []
        knee_trajectory = []
        hip_trajectory = []

        for frame_data in landmarks_sequence:
            landmarks = frame_data['landmarks']

            # Side viewì—ì„œëŠ” ì¹´ë©”ë¼ ì¸¡ë©´ì— ë”°ë¼ ì ì ˆí•œ ë‹¤ë¦¬ ì„ íƒ
            if camera_view == 'left_side':
                # ì™¼ìª½ì—ì„œ ì´¬ì˜ -> ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ê°€ ë” ì˜ ë³´ì„
                ankle_idx = self.side_view_landmarks['right_ankle']
                heel_idx = self.side_view_landmarks['right_heel']
                knee_idx = self.side_view_landmarks['right_knee']
                hip_idx = self.side_view_landmarks['right_hip']
            else:  # right_side
                # ì˜¤ë¥¸ìª½ì—ì„œ ì´¬ì˜ -> ì™¼ìª½ ë‹¤ë¦¬ê°€ ë” ì˜ ë³´ì„
                ankle_idx = self.side_view_landmarks['left_ankle']
                heel_idx = self.side_view_landmarks['left_heel']
                knee_idx = self.side_view_landmarks['left_knee']
                hip_idx = self.side_view_landmarks['left_hip']

            if (ankle_idx < len(landmarks) and heel_idx < len(landmarks) and
                knee_idx < len(landmarks) and hip_idx < len(landmarks)):

                ankle = landmarks[ankle_idx]
                heel = landmarks[heel_idx]
                knee = landmarks[knee_idx]
                hip = landmarks[hip_idx]

                # Y ì¢Œí‘œ (ìˆ˜ì§ ìœ„ì¹˜) - side viewì—ì„œ ì¤‘ìš”
                ankle_trajectory.append({
                    'x': ankle['x'],
                    'y': ankle['y'],
                    'visibility': ankle['visibility'],
                    'timestamp': frame_data['timestamp']
                })

                heel_trajectory.append({
                    'x': heel['x'],
                    'y': heel['y'],
                    'visibility': heel['visibility'],
                    'timestamp': frame_data['timestamp']
                })

                knee_trajectory.append({
                    'x': knee['x'],
                    'y': knee['y'],
                    'visibility': knee['visibility'],
                    'timestamp': frame_data['timestamp']
                })

                hip_trajectory.append({
                    'x': hip['x'],
                    'y': hip['y'],
                    'visibility': hip['visibility'],
                    'timestamp': frame_data['timestamp']
                })

        return {
            'ankle_trajectory': ankle_trajectory,
            'heel_trajectory': heel_trajectory,
            'knee_trajectory': knee_trajectory,
            'hip_trajectory': hip_trajectory,
            'camera_view': camera_view,
            'primary_limb': 'right' if camera_view == 'left_side' else 'left'
        }

    def detect_gait_events(self, trajectories):
        """Side viewì—ì„œ ë³´í–‰ ì´ë²¤íŠ¸ (heel strike, toe off) ê²€ì¶œ"""
        heel_trajectory = trajectories['heel_trajectory']
        ankle_trajectory = trajectories['ankle_trajectory']

        if len(heel_trajectory) < 10:
            return {'heel_strikes': [], 'toe_offs': [], 'gait_cycles': []}

        # Y ì¢Œí‘œ (ìˆ˜ì§) ë³€í™”ë¡œ heel strike ê²€ì¶œ
        heel_y = [point['y'] for point in heel_trajectory]
        ankle_y = [point['y'] for point in ankle_trajectory]

        # ë°œê°€ë½-ë°œëª© ë†’ì´ ì°¨ì´ë¡œ toe off ê²€ì¶œ
        heel_ankle_diff = [abs(h - a) for h, a in zip(heel_y, ankle_y)]

        # Simple peak detection for heel strikes (local minima in Y)
        heel_strikes = []
        toe_offs = []

        # ìµœì €ì  (heel strike) ì°¾ê¸°
        for i in range(1, len(heel_y) - 1):
            if heel_y[i] < heel_y[i-1] and heel_y[i] < heel_y[i+1]:
                if len(heel_strikes) == 0 or i - heel_strikes[-1] > 10:  # ìµœì†Œ ê°„ê²©
                    heel_strikes.append(i)

        # ìµœê³ ì  (toe off) ì°¾ê¸°
        for i in range(1, len(heel_ankle_diff) - 1):
            if heel_ankle_diff[i] > heel_ankle_diff[i-1] and heel_ankle_diff[i] > heel_ankle_diff[i+1]:
                if len(toe_offs) == 0 or i - toe_offs[-1] > 10:  # ìµœì†Œ ê°„ê²©
                    toe_offs.append(i)

        # ë³´í–‰ ì£¼ê¸° êµ¬ì„± (heel strike to heel strike)
        gait_cycles = []
        for i in range(len(heel_strikes) - 1):
            start_frame = heel_strikes[i]
            end_frame = heel_strikes[i + 1]

            # ì´ ì£¼ê¸° ë‚´ì˜ toe off ì°¾ê¸°
            cycle_toe_offs = [to for to in toe_offs if start_frame < to < end_frame]

            gait_cycles.append({
                'start_frame': start_frame,
                'end_frame': end_frame,
                'duration_frames': end_frame - start_frame,
                'heel_strike_frame': start_frame,
                'toe_off_frames': cycle_toe_offs,
                'start_timestamp': heel_trajectory[start_frame]['timestamp'],
                'end_timestamp': heel_trajectory[end_frame]['timestamp'],
                'duration_seconds': heel_trajectory[end_frame]['timestamp'] - heel_trajectory[start_frame]['timestamp']
            })

        return {
            'heel_strikes': heel_strikes,
            'toe_offs': toe_offs,
            'gait_cycles': gait_cycles,
            'total_cycles': len(gait_cycles)
        }

    def calculate_gait_parameters(self, trajectories, gait_events, video_info):
        """Side viewì—ì„œ ì„ìƒì  ë³´í–‰ íŒŒë¼ë¯¸í„° ê³„ì‚°"""
        gait_cycles = gait_events['gait_cycles']

        if len(gait_cycles) < 2:
            return None

        # ê¸°ë³¸ í†µê³„
        cycle_durations = [cycle['duration_seconds'] for cycle in gait_cycles]
        avg_cycle_duration = np.mean(cycle_durations)
        cycle_variability = np.std(cycle_durations) / avg_cycle_duration if avg_cycle_duration > 0 else 0

        # ì¼€ì´ë˜ìŠ¤ ê³„ì‚° (steps/minute)
        cadence = 60 / avg_cycle_duration if avg_cycle_duration > 0 else 0

        # ë°œëª© ë†’ì´ ë³€í™” ë¶„ì„
        ankle_trajectory = trajectories['ankle_trajectory']
        ankle_y_values = [point['y'] for point in ankle_trajectory]
        foot_clearance = max(ankle_y_values) - min(ankle_y_values) if ankle_y_values else 0

        # ë¬´ë¦ ê°ë„ ë³€í™” (ê°„ì ‘ ì¶”ì •)
        knee_trajectory = trajectories['knee_trajectory']
        hip_trajectory = trajectories['hip_trajectory']

        knee_hip_distances = []
        for i in range(min(len(knee_trajectory), len(hip_trajectory))):
            knee = knee_trajectory[i]
            hip = hip_trajectory[i]
            distance = np.sqrt((knee['x'] - hip['x'])**2 + (knee['y'] - hip['y'])**2)
            knee_hip_distances.append(distance)

        knee_flexion_range = max(knee_hip_distances) - min(knee_hip_distances) if knee_hip_distances else 0

        # ìì„¸ ì•ˆì •ì„± (ê¶¤ì ì˜ ë¶€ë“œëŸ¬ì›€)
        ankle_x_values = [point['x'] for point in ankle_trajectory]
        step_width_variability = np.std(ankle_x_values) if len(ankle_x_values) > 1 else 0

        # í‰ê·  ê°€ì‹œì„± (landmark ê²€ì¶œ í’ˆì§ˆ)
        all_visibilities = []
        for traj in [ankle_trajectory, knee_trajectory, hip_trajectory]:
            for point in traj:
                all_visibilities.append(point['visibility'])
        avg_visibility = np.mean(all_visibilities) if all_visibilities else 0

        return {
            'cadence': cadence,
            'avg_cycle_duration': avg_cycle_duration,
            'cycle_variability': cycle_variability,
            'foot_clearance': foot_clearance,
            'knee_flexion_range': knee_flexion_range,
            'step_width_variability': step_width_variability,
            'avg_visibility': avg_visibility,
            'total_gait_cycles': len(gait_cycles),
            'gait_symmetry': 1.0 - cycle_variability,  # ë†’ì„ìˆ˜ë¡ ëŒ€ì¹­ì 
            'postural_stability': 1.0 - step_width_variability,  # ë†’ì„ìˆ˜ë¡ ì•ˆì •ì 
            'movement_efficiency': avg_visibility * (1.0 - cycle_variability),
            'primary_limb': trajectories['primary_limb'],
            'camera_view': trajectories['camera_view']
        }

    def process_single_video(self, video_pair):
        """ë‹¨ì¼ side view ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        video_path = video_pair['video_file']
        video_id = video_pair['video_id']
        camera_view = video_pair['camera_view']
        gait_pattern = video_pair['gait_pattern']

        print(f"   ğŸ“ ì²˜ë¦¬ ì¤‘: {video_id} ({camera_view}) - {gait_pattern}")

        try:
            # 1. Pose landmarks ì¶”ì¶œ
            landmarks_data, status = self.extract_pose_landmarks(video_path)

            if landmarks_data is None:
                return {
                    'video_info': video_pair,
                    'success': False,
                    'error': status,
                    'processing_time': None
                }

            # 2. ë³´í–‰ ê¶¤ì  ì¶”ì¶œ
            trajectories = self.extract_gait_cycle_features(landmarks_data, camera_view)

            # 3. ë³´í–‰ ì´ë²¤íŠ¸ ê²€ì¶œ
            gait_events = self.detect_gait_events(trajectories)

            # 4. ì„ìƒ íŒŒë¼ë¯¸í„° ê³„ì‚°
            gait_parameters = self.calculate_gait_parameters(trajectories, gait_events, video_pair)

            if gait_parameters is None:
                return {
                    'video_info': video_pair,
                    'success': False,
                    'error': "ì¶©ë¶„í•œ ë³´í–‰ ì£¼ê¸° ê²€ì¶œ ì‹¤íŒ¨",
                    'processing_time': None
                }

            # ì„±ê³µì ì¸ ì²˜ë¦¬ ê²°ê³¼
            return {
                'video_info': video_pair,
                'success': True,
                'landmarks_data': {
                    'total_frames': landmarks_data['total_frames'],
                    'successful_frames': landmarks_data['successful_frames'],
                    'success_rate': landmarks_data['success_rate'],
                    'fps': landmarks_data['fps']
                },
                'trajectories': {
                    'ankle_points': len(trajectories['ankle_trajectory']),
                    'heel_points': len(trajectories['heel_trajectory']),
                    'knee_points': len(trajectories['knee_trajectory']),
                    'hip_points': len(trajectories['hip_trajectory']),
                    'primary_limb': trajectories['primary_limb']
                },
                'gait_events': gait_events,
                'gait_parameters': gait_parameters,
                'error': None
            }

        except Exception as e:
            return {
                'video_info': video_pair,
                'success': False,
                'error': f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}",
                'processing_time': None
            }

    def process_all_side_view_videos(self, max_videos=None):
        """ëª¨ë“  side view ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        print(f"\nğŸ¥ Side view ë¹„ë””ì˜¤ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘...")

        if not self.side_view_pairs:
            self.load_side_view_pairs()

        videos_to_process = self.side_view_pairs[:max_videos] if max_videos else self.side_view_pairs
        self.processing_stats['total_videos'] = len(videos_to_process)

        print(f"   ì²˜ë¦¬í•  ë¹„ë””ì˜¤ ìˆ˜: {len(videos_to_process)}ê°œ")

        for i, video_pair in enumerate(videos_to_process, 1):
            print(f"\nğŸ“ [{i}/{len(videos_to_process)}]", end=" ")

            result = self.process_single_video(video_pair)
            self.extraction_results.append(result)

            if result['success']:
                self.processing_stats['successful_extractions'] += 1
                print(f"âœ… ì„±ê³µ")
            else:
                self.processing_stats['failed_extractions'] += 1
                print(f"âŒ ì‹¤íŒ¨: {result['error']}")

        # ìµœì¢… í†µê³„
        success_rate = (self.processing_stats['successful_extractions'] /
                       self.processing_stats['total_videos']) * 100

        print(f"\nğŸ“Š Side view ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   ì´ ë¹„ë””ì˜¤: {self.processing_stats['total_videos']}ê°œ")
        print(f"   ì„±ê³µ: {self.processing_stats['successful_extractions']}ê°œ")
        print(f"   ì‹¤íŒ¨: {self.processing_stats['failed_extractions']}ê°œ")
        print(f"   ì„±ê³µë¥ : {success_rate:.1f}%")

        return self.extraction_results

    def save_results(self, output_file=None):
        """ì²˜ë¦¬ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        if output_file is None:
            output_file = f"gavd_side_view_mediapipe_results_{timestamp}.json"

        results_data = {
            'extraction_info': {
                'timestamp': timestamp,
                'side_view_only': True,
                'processing_stats': self.processing_stats,
                'mediapipe_config': {
                    'model_complexity': 1,
                    'min_detection_confidence': 0.5,
                    'min_tracking_confidence': 0.5
                }
            },
            'results': self.extraction_results
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        return output_file

    def generate_analysis_report(self):
        """Side view ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if not self.extraction_results:
            print("âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        successful_results = [r for r in self.extraction_results if r['success']]

        print(f"\nğŸ“‹ GAVD Side View MediaPipe ë¶„ì„ ë³´ê³ ì„œ")
        print(f"{'='*60}")

        # ê¸°ë³¸ í†µê³„
        print(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        print(f"   ì´ ë¹„ë””ì˜¤: {len(self.extraction_results)}ê°œ")
        print(f"   ì„±ê³µì  ì²˜ë¦¬: {len(successful_results)}ê°œ")
        print(f"   ì‹¤íŒ¨: {len(self.extraction_results) - len(successful_results)}ê°œ")

        if not successful_results:
            print("âŒ ì„±ê³µì ì¸ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì¹´ë©”ë¼ ë·° ë¶„ì„
        view_stats = {}
        for result in successful_results:
            view = result['video_info']['camera_view']
            view_stats[view] = view_stats.get(view, 0) + 1

        print(f"\nğŸ“· ì¹´ë©”ë¼ ë·°ë³„ ì„±ê³µ:")
        for view, count in view_stats.items():
            print(f"   {view}: {count}ê°œ")

        # ë³´í–‰ íŒ¨í„´ ë¶„ì„
        pattern_stats = {}
        for result in successful_results:
            pattern = result['video_info']['gait_pattern']
            pattern_stats[pattern] = pattern_stats.get(pattern, 0) + 1

        print(f"\nğŸ¦´ ë³´í–‰ íŒ¨í„´ë³„ ì„±ê³µ:")
        for pattern, count in pattern_stats.items():
            print(f"   {pattern}: {count}ê°œ")

        # ì„ìƒ íŒŒë¼ë¯¸í„° í†µê³„
        cadences = []
        cycle_variabilities = []
        foot_clearances = []
        gait_symmetries = []

        for result in successful_results:
            if 'gait_parameters' in result and result['gait_parameters']:
                params = result['gait_parameters']
                cadences.append(params['cadence'])
                cycle_variabilities.append(params['cycle_variability'])
                foot_clearances.append(params['foot_clearance'])
                gait_symmetries.append(params['gait_symmetry'])

        if cadences:
            print(f"\nğŸš¶ ë³´í–‰ íŒŒë¼ë¯¸í„° í†µê³„:")
            print(f"   ì¼€ì´ë˜ìŠ¤: {np.mean(cadences):.1f} Â± {np.std(cadences):.1f} steps/min")
            print(f"   ì£¼ê¸° ë³€ë™ì„±: {np.mean(cycle_variabilities):.3f} Â± {np.std(cycle_variabilities):.3f}")
            print(f"   ë°œ ë†’ì´ ë³€í™”: {np.mean(foot_clearances):.3f} Â± {np.std(foot_clearances):.3f}")
            print(f"   ë³´í–‰ ëŒ€ì¹­ì„±: {np.mean(gait_symmetries):.3f} Â± {np.std(gait_symmetries):.3f}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“ GAVD Side View MediaPipe ë³´í–‰ ë¶„ì„ê¸°")
    print("=" * 50)

    # GAVDDatasetAnalyzer ì´ˆê¸°í™”
    from gavd_dataset_analyzer import GAVDDatasetAnalyzer
    gavd_analyzer = GAVDDatasetAnalyzer()
    gavd_analyzer.load_clinical_annotations()

    # Side View MediaPipe ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = GAVDSideViewMediaPipeExtractor(gavd_analyzer)

    try:
        # 1. Side view ìŒ ë¡œë“œ
        extractor.load_side_view_pairs()

        # 2. í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ (ì²˜ìŒ 10ê°œ)
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ (ìµœëŒ€ 10ê°œ ë¹„ë””ì˜¤)")
        extractor.process_all_side_view_videos(max_videos=10)

        # 3. ê²°ê³¼ ì €ì¥
        output_file = extractor.save_results()

        # 4. ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        extractor.generate_analysis_report()

        print(f"\nğŸ‰ Side view MediaPipe ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {output_file}")

    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()